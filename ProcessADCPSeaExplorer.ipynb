{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46cba559-8f4d-4657-a45a-56343e741b60",
   "metadata": {},
   "source": [
    "# - TODO LIST\n",
    "- Write better RBR Legato correction\n",
    "- Test out Robert Todd's linear method\n",
    "- Implement inverse method\n",
    "- variance plots\n",
    "- reread Todd\n",
    "- SNR QC\n",
    "- STD in Up metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b56b2-0832-49df-8a11-817dbfa37025",
   "metadata": {},
   "source": [
    "# I. Settings and initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9aa04-7a48-4629-9999-3ed3a2e54c88",
   "metadata": {},
   "source": [
    "## 1.1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaaedfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    'correctRBRLag' : False, # Perform Garau lag correction (TODO, pretty crappy)\n",
    "    'correctADCPHeading' : False,\n",
    "    'ADCP_discardFirstBin' : True, # First bin often very affected by glider, good to discard, in future we should extend blanking distance\n",
    "    'ADCP_correlationThreshold': 60,\n",
    "    'ADCP_amplitudeThreshold' : 75,\n",
    "    'ADCP_velocityThreshold' : 0.6,\n",
    "    'correctXshear' : True,\n",
    "    'correctYshear' : True,\n",
    "    'correctZshear' : True,\n",
    "    'correctZZshear' : True,\n",
    "    }\n",
    "# reprocessRawGliderData = False\n",
    "\n",
    "# correctOxygenLag = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111c6413-310a-47fc-84df-ae18138f9cde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2. Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f79d0c-da98-45dd-a9d8-11d3a7c85518",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bornholm\n",
    "# adcp_path = 'D:/Storage/VOTO_ADCP/Bornholm/sea063_M22.ad2cp.00000*.nc'\n",
    "# filename = 'D:/Storage/Dropbox/Jupyter/Data/Bornholm_SEA063_M22.pqt'\n",
    "# top_mounted = True\n",
    "\n",
    "### Skagerak\n",
    "# adcp_path = 'D:/Storage/VOTO_ADCP/Skag/sea045_M44.ad2cp.00000*.nc'\n",
    "# filename = 'D:/Storage/Dropbox/Jupyter/Data/Skag_SEA045_M44.pqt'\n",
    "# top_mounted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7584c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### OMAN DATASETS\n",
    "\n",
    "# adcp_path = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/211105_Dep1_post/ADCP_proc/sea057_M35_1.ad2cp.00000*.nc'\n",
    "# filename = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/211105_Dep1_post/Oman_deployment_1.pqt'\n",
    "# top_mounted = False\n",
    "\n",
    "# adcp_path = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/211118_Dep2_post/ADCP/sea057_M38.ad2cp.00000*.nc'\n",
    "# filename = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/211118_Dep2_post/Oman_deployment_2.pqt'\n",
    "# top_mounted = False\n",
    "\n",
    "adcp_path = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/211220_Dep3_post/ADCP/sea057_M40.ad2cp.00000*.nc'\n",
    "filename = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/211220_Dep3_post/Oman_deployment_3.pqt'\n",
    "top_mounted = False\n",
    "\n",
    "# adcp_path = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/220126_Dep4_post/ADCP/sea057_M43.ad2cp.00000*.nc'\n",
    "# filename = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/220126_Dep4_post/Oman_deployment_4.pqt'\n",
    "# top_mounted = False\n",
    "\n",
    "# adcp_path = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/220224_Dep5_post/ADCP/sea057_M45.ad2cp.00000*.nc'\n",
    "# filename = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/220224_Dep5_post/Oman_deployment_5.pqt'\n",
    "# top_mounted = False\n",
    "\n",
    "# adcp_path = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/220327_Dep6_post/ADCP/sea057_M47.ad2cp.00000*.nc'\n",
    "# filename = 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/220327_Dep6_post/Oman_deployment_6.pqt'\n",
    "# top_mounted = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117eaf07-8c72-4817-aff9-aed4c5a66770",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.3. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5691e0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, gc, sys, warnings\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(r'D:/Storage/Repositories/SeaExplorerTools')\n",
    "import SXBQ as sx\n",
    "import BYQtools as byq\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from datetime import datetime as dt\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy.interpolate import interp1d, interp2d\n",
    "from scipy.optimize import fsolve, fmin\n",
    "from scipy.signal import convolve as conv\n",
    "\n",
    "import gsw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cmocean.cm as cmo\n",
    "\n",
    "warnings.filterwarnings(action='ignore', message='Mean of empty slice')\n",
    "warnings.filterwarnings(action='ignore', message='invalid value encountered in divide')\n",
    "\n",
    "sns.set(font='Franklin Gothic Book',\n",
    "        rc={\n",
    "         'axes.axisbelow': False,\n",
    "         'axes.edgecolor': 'Black',\n",
    "         'axes.facecolor': 'lightgrey',\n",
    "         'axes.grid': False,\n",
    "         'axes.labelcolor': 'darkgrey',\n",
    "         'axes.spines.right': True,\n",
    "         'axes.spines.top': True,\n",
    "         'figure.facecolor': 'white',\n",
    "         'lines.solid_capstyle': 'round',\n",
    "         'patch.edgecolor': 'k',\n",
    "         'patch.force_edgecolor': True,\n",
    "         'text.color': 'dimgrey',\n",
    "         'xtick.bottom': False,\n",
    "         'xtick.color': 'dimgrey',\n",
    "         'xtick.direction': 'out',\n",
    "         'xtick.top': False,\n",
    "         'ytick.color': 'dimgrey',\n",
    "         'ytick.direction': 'out',\n",
    "         'ytick.left': False,\n",
    "         'ytick.right': False},\n",
    "         font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db80e52-60ef-4b2f-a9c0-c4803d4bf291",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.4. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44facd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def RunningMedian(x,N):\n",
    "    grid = np.ones((len(x)+2*N, 1 + 2*N ))*np.NaN\n",
    "    for istep in range(np.shape(grid)[1]):\n",
    "        grid[istep:len(x)+istep, istep] = x\n",
    "    return np.nanmedian(grid,axis=1)[N:-N]\n",
    "\n",
    "def RunningMax(x,N):\n",
    "    grid = np.ones((len(x)+2*N, 1 + 2*N ))*np.NaN\n",
    "    for istep in range(np.shape(grid)[1]):\n",
    "        grid[istep:len(x)+istep, istep] = x\n",
    "    return np.nanmax(grid,axis=1)[N:-N]\n",
    "\n",
    "def RunningMin(x,N):\n",
    "    grid = np.ones((len(x)+2*N, 1 + 2*N ))*np.NaN\n",
    "    for istep in range(np.shape(grid)[1]):\n",
    "        grid[istep:len(x)+istep, istep] = x\n",
    "    return np.nanmin(grid,axis=1)[N:-N]\n",
    "\n",
    "def RunningMean(x,N):\n",
    "    grid = np.ones((len(x)+2*N, 1 + 2*N ))*np.NaN\n",
    "    for istep in range(np.shape(grid)[1]):\n",
    "        grid[istep:len(x)+istep, istep] = x\n",
    "    return np.nanmean(grid,axis=1)[N:-N]\n",
    "\n",
    "def interp(x,y,xi):\n",
    "    _gg = np.isfinite(x+y)\n",
    "    return interp1d(x[_gg], y[_gg], bounds_error=False, fill_value=np.NaN)(xi)\n",
    "\n",
    "def rmsd(x):\n",
    "    return np.sqrt(np.nanmean(x**2))\n",
    "\n",
    "def plog(msg):\n",
    "    print(str(dt.now().replace(microsecond=0))+' : '+msg)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e385ddea",
   "metadata": {},
   "source": [
    "# II. Load and process glider data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198151b-71e6-4bad-adfb-a440e8fa6879",
   "metadata": {},
   "source": [
    "## 2.1. Load and split profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece3494",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data = sx.sxdf(['D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/220327_Dep6_post/PLD/logs/sea057.47.pld1.raw*.gz',\n",
    "#                 'D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/220327_Dep6_post/NAV/logs/sea057.47.gli.sub*.gz'])\n",
    "# data.process_basic_variables()\n",
    "# data.save('D:/Storage/Dropbox/WorkGU/21-06 Oman HAB Deployments/Deployments/220327_Dep6_post/Oman_deployment_6.pqt')\n",
    "data = sx.load(filename)\n",
    "data.process_basic_variables()\n",
    "plog('Loaded glider data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf854c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _process():\n",
    "    #data.data.sort_values('Timestamp', ignore_index=True, inplace=True)\n",
    "    data.median_resample()\n",
    "\n",
    "    _gd = np.isfinite(data.data['diveNum'].values)\n",
    "    _, _tmp = np.unique( np.round(data.data['diveNum'].values[_gd]) ,return_inverse=True)\n",
    "\n",
    "    data.data.loc[_gd,'diveNum'] = np.round(_tmp+1)\n",
    "    data.data['diveNum'] = data.data['diveNum'].interpolate('nearest')\n",
    "        \n",
    "    data.data['profileNum'] = data.data['diveNum'].values*2\n",
    "    _tmp = data.data['NAV_RESOURCE'].interpolate('nearest').values\n",
    "    ind = (_tmp == 100) | (_tmp == 110) | (_tmp == 116)\n",
    "    data.data.loc[ind,'profileNum'] = data.data.loc[ind,'profileNum'] - 1\n",
    "    \n",
    "    plog('Glider profiles processed')\n",
    "\n",
    "_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5184f-b09b-405c-bfac-d5888cacf714",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2. Process the RBR temperature and salinity data\n",
    "### Correct RBR pressure bias for this series of sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8e46c-538a-4662-952d-23cc289ad0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process():\n",
    "    X2 = 1.8e-06\n",
    "    X3 = -9.472e-10\n",
    "    X4= 2.112e-13\n",
    "    Cmeas = data.data.LEGATO_CONDUCTIVITY.values\n",
    "    Pmeas = data.data.LEGATO_PRESSURE.values\n",
    "    data.data.LEGATO_CONDUCTIVITY =  Cmeas / (1 + X2*Pmeas + X3*Pmeas**2 + X4*Pmeas**3)\n",
    "    data.data.LEGATO_SALINITY = gsw.SP_from_C(data.data.LEGATO_CONDUCTIVITY.values, data.data.LEGATO_TEMPERATURE.values, Pmeas)\n",
    "    plog('Performed pressure correction on salinity data')\n",
    "    \n",
    "_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce2cd8a-8613-4959-8d37-bec5053eaa06",
   "metadata": {},
   "source": [
    "### Correct for RBR sensor lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc659d-bb7a-41f2-8bb8-398501652a5e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if options['correctRBRLag']:\n",
    "    data = sx.correctSalinityGarau(data)\n",
    "    plog('Corrected RBR data for lag')\n",
    "else:\n",
    "    data.data['salinity'] = data.data.LEGATO_SALINITY\n",
    "    data.data['temperature'] = data.data.LEGATO_TEMPERATURE\n",
    "    plog('Skipped RBR lag correction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002066f8-c376-4e7e-a829-20206b8e52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _verify():\n",
    "    plt.figure(figsize=(20,5))\n",
    "\n",
    "    dives = data.data.diveNum.values\n",
    "    dives = np.unique(dives[np.isfinite(dives)])\n",
    "    dives = np.round(np.percentile(dives,[20,40,60,80]))\n",
    "\n",
    "    xlims = np.nanpercentile(data.data.salinity.values,[1,99])\n",
    "\n",
    "    for idx in range(len(dives)):\n",
    "        plt.subplot(1,len(dives),idx+1)\n",
    "        dn = data.data.diveNum==dives[idx]\n",
    "        plt.plot(data.data.LEGATO_SALINITY[dn],data.data.LEGATO_TEMPERATURE[dn],':r')\n",
    "        plt.plot(data.data.salinity[dn],data.data.temperature[dn],'-b',alpha=0.5)\n",
    "        plt.title('Dive '+str(dives[idx]))\n",
    "        plt.xlim(xlims)\n",
    "\n",
    "_verify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deda719-7930-4d84-bc86-15a54d2d7ea5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## 2.3. Calculate derived variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3200535-ac92-4616-95a8-fdf889a24aca",
   "metadata": {},
   "source": [
    "### TEOS-10 T&S dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd3628",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ancillary variables\n",
    "def _process(data):\n",
    "    data['sa'] = gsw.SA_from_SP(data['salinity'].values,data['LEGATO_PRESSURE'].values,data['longitude'].values,data['latitude'].values)\n",
    "    \n",
    "    data['ct'] = gsw.CT_from_t(data['sa'].values,data['temperature'].values,data['LEGATO_PRESSURE'].values)\n",
    "    \n",
    "    data['sigma0'] = gsw.sigma0(data['sa'].values,data['ct'].values)\n",
    "    \n",
    "    data['soundspeed'] = gsw.sound_speed(data['sa'].values,data['ct'].values,data['LEGATO_PRESSURE'].values)\n",
    "    \n",
    "    data['depth'] = -gsw.z_from_p(data['LEGATO_PRESSURE'].values,data['latitude'].values)\n",
    "    \n",
    "    data['date_float'] = data.Timestamp.values.astype('float')\n",
    "    \n",
    "    plog('Calculated T&S derived variables')\n",
    "    return data\n",
    "\n",
    "data.data = _process(data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee11cad-4bca-4a46-b256-56278f708464",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Dissolved oxygen ( TODO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876ac95-2667-45a9-8cf4-d85564689308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oxygen TODO\n",
    "# missing lag correction\n",
    "def _process(data):\n",
    "    o2_sol = gsw.O2sol(data['sa'],data['ct'],data['LEGATO_PRESSURE'],data['longitude'],data['latitude'])\n",
    "    o2_sat =  data['AROD_FT_DO'] / gsw.O2sol( data['sa']*0, data['AROD_FT_TEMP'], data['LEGATO_PRESSURE']*0,data['longitude'],data['latitude'])\n",
    "    data['o2'] = o2_sat * o2_sol\n",
    "    data['o2_sat'] = o2_sat * 100\n",
    "    data['aou'] = o2_sol - data['o2']\n",
    "    plog('Calculated oxygen variables')\n",
    "    return data\n",
    "    \n",
    "data.data = _process(data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a07480-4dec-4763-9254-f9aaf097bcd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optical particulate backscatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7796f3-8b6a-4517-ae4a-3564141b5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process(data):\n",
    "    def calculate_bbp(beta_total, beam_angle=117, wavelength=700):\n",
    "        # Scaled output from SeaExplorer gives us Beta for water and particple.\n",
    "        # https://oceanobservatories.org/wp-content/uploads/2015/10/1341-00540_Data_Product_SPEC_FLUBSCT_OOI.pdf\n",
    "        beta_sw = byq.betasw_ZHH2009(data.temperature.values,data.salinity.values, wavelength, beam_angle)\n",
    "        beta_p = beta_total - beta_sw\n",
    "        Chi_p = 1.08 # For 117* angle (Sullivan & Twardowski, 2009)\n",
    "        # Chi_p = 1.17 # For 140* angle (Sullivan & Twardowski, 2009)\n",
    "        bbp = 2 * np.pi * Chi_p * beta_p # in m-1\n",
    "        return bbp\n",
    "    \n",
    "    obs = [x for x in data.columns if ('FL' == x[:2]) & ('_BB_' in x) & ('SCALED' in x)]\n",
    "    for idx in range(len(obs)):\n",
    "        var = obs[idx]\n",
    "        wl = int(''.join(filter(str.isdigit, var)))\n",
    "        plog('Calculating particulate backscatter at '+str(wl)+' nm.')\n",
    "        data['bbp_'+str(wl)],_,_ = calculate_bbp(data[var].values, wavelength=wl)\n",
    "    return data\n",
    "\n",
    "data.data = _process(data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7658fba6-f21e-465a-9675-57374c0b6b05",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## 2.4. Define gridding axis based on glider profile times and data range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98021f80-8b03-46a5-93cd-043445aa5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = 0.5\n",
    "yaxis = np.arange(0,np.nanmax(np.ceil(data.data.LEGATO_PRESSURE.values)),y_res)\n",
    "xaxis = data.data.date_float.groupby(data.data.profileNum).agg('mean').index\n",
    "taxis = pd.to_datetime(data.data.date_float.groupby(data.data.profileNum).agg('mean').values)\n",
    "days = np.unique(data.data.Timestamp.round('D'))\n",
    "   \n",
    "out = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e63bf0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# III. ADCP Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6d400",
   "metadata": {},
   "source": [
    "## 3.1. Load ADCP AVG data and xarray adjust coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4d937-9da5-4b72-bb50-2438b92339bb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ADCP = xr.open_mfdataset(adcp_path,group='Data/Average')\n",
    "ADCP_settings = xr.open_mfdataset(glob(adcp_path)[0],group='Config')\n",
    "bin_size = ADCP_settings.attrs['avg_cellSize']\n",
    "blanking_distance = ADCP_settings.attrs['avg_blankingDistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff87615b-c780-42dc-8e5b-47a20a534fcc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ADCP = ADCP.assign_coords(\n",
    "    Latitude=(\"time\", \n",
    "              interp( data.data['Timestamp'].values.astype('float'), data.data['latitude'], ADCP.time.values.astype('float') ) ))\n",
    "\n",
    "ADCP = ADCP.assign_coords(\n",
    "    profileNum=(\"time\", \n",
    "                np.round(interp(data.data['Timestamp'].values.astype('float'), data.data['profileNum'], ADCP.time.values.astype('float'))) ))\n",
    "\n",
    "ADCP = ADCP.assign_coords(\n",
    "    Depth=(\"time\", -gsw.z_from_p(ADCP['Pressure'].values,ADCP['Latitude'].values)))\n",
    "\n",
    "ADCP = ADCP.assign_coords(\n",
    "    bin=(\"Velocity Range\", np.arange(len(ADCP['Velocity Range'].values))))\n",
    "ADCP = ADCP.swap_dims({'Velocity Range':'bin'})\n",
    "\n",
    "ADCP = ADCP.assign_coords(\n",
    "    bin=(\"Correlation Range\", np.arange(len(ADCP['Correlation Range'].values))))\n",
    "ADCP = ADCP.swap_dims({'Correlation Range':'bin'})\n",
    "\n",
    "ADCP = ADCP.assign_coords(\n",
    "    bin=(\"Amplitude Range\", np.arange(len(ADCP['Amplitude Range'].values))))\n",
    "ADCP = ADCP.swap_dims({'Amplitude Range':'bin'})\n",
    "\n",
    "plog('Finished loading ADCP data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981aed6f-8805-4eee-9ce9-62f4ebbaec77",
   "metadata": {},
   "source": [
    "## 3.2 Correct ADCP positioning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e3695-427f-4711-97c9-462fdf87d334",
   "metadata": {},
   "source": [
    "### Calculate depth of ADCP bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1435a4-7662-4923-b992-8b3e24cf0807",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remapADCPdepth(ADCP, bin_size, blanking_distance, top_mounted=top_mounted):\n",
    "    if top_mounted:\n",
    "        direction = 1\n",
    "        theta_rad_1 = np.arccos(  np.cos(np.deg2rad(47.5 - ADCP['Pitch']))  * np.cos(np.deg2rad(ADCP['Roll']))  )\n",
    "        theta_rad_2 = np.arccos(  np.cos(np.deg2rad(25 -   ADCP['Roll'] ))  * np.cos(np.deg2rad(ADCP['Pitch']))  )\n",
    "        theta_rad_3 = np.arccos(  np.cos(np.deg2rad(47.5 + ADCP['Pitch']))  * np.cos(np.deg2rad(ADCP['Roll']))  )\n",
    "        theta_rad_4 = np.arccos(  np.cos(np.deg2rad(25 +   ADCP['Roll'] ))  * np.cos(np.deg2rad(ADCP['Pitch']))  )\n",
    "    else:\n",
    "        direction = -1\n",
    "        theta_rad_1 = np.arccos(  np.cos(np.deg2rad(47.5 + ADCP['Pitch']))  * np.cos(np.deg2rad(ADCP['Roll']))  )\n",
    "        theta_rad_2 = np.arccos(  np.cos(np.deg2rad(25 +   ADCP['Roll'] ))  * np.cos(np.deg2rad(ADCP['Pitch']))  )\n",
    "        theta_rad_3 = np.arccos(  np.cos(np.deg2rad(47.5 - ADCP['Pitch']))  * np.cos(np.deg2rad(ADCP['Roll']))  )\n",
    "        theta_rad_4 = np.arccos(  np.cos(np.deg2rad(25 -   ADCP['Roll'] ))  * np.cos(np.deg2rad(ADCP['Pitch']))  )\n",
    "        \n",
    "    # Upward facing ADCP, so beam 1 ~= 22 deg on the way up, beam 3 on the way down\n",
    "    # Returns angles of each beam from the UP direction\n",
    "    \n",
    "    z_bin_distance = blanking_distance + np.arange(len(ADCP.bin))*bin_size + 0.5*bin_size\n",
    "    \n",
    "    ADCP['D1'] = (\n",
    "                   ['time','bin'],\n",
    "                   np.tile(ADCP['Depth'], (len(ADCP.bin), 1)).T \\\n",
    "                     - direction \\\n",
    "                     * np.tile(z_bin_distance/np.cos(np.deg2rad(47.5)), (len(ADCP.time), 1)) \\\n",
    "                     * np.tile(np.cos(theta_rad_1), (len(ADCP.bin), 1)).T \\\n",
    "                   )\n",
    "    ADCP['D2'] = (\n",
    "                   ['time','bin'],\n",
    "                   np.tile(ADCP['Depth'], (len(ADCP.bin), 1)).T \\\n",
    "                    - direction \\\n",
    "                    * np.tile(z_bin_distance/np.cos(np.deg2rad(25)), (len(ADCP.time), 1)) \\\n",
    "                    * np.tile(np.cos(theta_rad_2), (len(ADCP.bin), 1)).T \\\n",
    "                  )\n",
    "    ADCP['D3'] = (\n",
    "                   ['time','bin'],\n",
    "                   np.tile(ADCP['Depth'], (len(ADCP.bin), 1)).T \\\n",
    "                    - direction \\\n",
    "                    * np.tile(z_bin_distance/np.cos(np.deg2rad(47.5)), (len(ADCP.time), 1)) \\\n",
    "                    * np.tile(np.cos(theta_rad_3), (len(ADCP.bin), 1)).T \\\n",
    "                  )\n",
    "    ADCP['D4'] = (\n",
    "                   ['time','bin'],\n",
    "                   np.tile(ADCP['Depth'], (len(ADCP.bin), 1)).T \\\n",
    "                    - direction \\\n",
    "                    * np.tile(z_bin_distance/np.cos(np.deg2rad(25)), (len(ADCP.time), 1)) \\\n",
    "                    * np.tile(np.cos(theta_rad_4), (len(ADCP.bin), 1)).T \\\n",
    "                  )  \n",
    "    \n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=(20,4))\n",
    "    x = np.arange(1000)\n",
    "    \n",
    "    times = np.tile(ADCP.time[x].values, (len(ADCP['bin']), 1)).T\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(ADCP.time[x],ADCP.Pitch[x])\n",
    "    plt.ylabel('Pitch')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.scatter(ADCP.time[x],ADCP.Pressure[x],5,'k')\n",
    "    plt.scatter(times.flatten(),ADCP.isel(time=x)['D1'].values.flatten(),1,'g',alpha=0.2)\n",
    "    plt.scatter(times.flatten(),ADCP.isel(time=x)['D2'].values.flatten(),1,'y',alpha=0.2)\n",
    "    plt.scatter(times.flatten(),ADCP.isel(time=x)['D3'].values.flatten(),1,'b',alpha=0.2)\n",
    "    plt.scatter(times.flatten(),ADCP.isel(time=x)['D4'].values.flatten(),1,'r',alpha=0.2)\n",
    "    plt.plot(ADCP.time[x],ADCP.Pressure[x],'k')\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    return ADCP\n",
    "\n",
    "ADCP = remapADCPdepth(ADCP,bin_size,blanking_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7644bc-abac-4da2-9163-f64d6558e76a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ADCP Heading correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7959a-999f-4318-a67c-022e1527546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process(ADCP):\n",
    "    \n",
    "    # # Get local geomagnetic target strength:\n",
    "    def getGeoMagStrength():    \n",
    "        lat = np.nanmedian(data.data.latitude)\n",
    "        lon = np.nanmedian(data.data.longitude)\n",
    "        date = pd.to_datetime(np.nanmean(data.data.Timestamp.values.astype('float')))\n",
    "        year = date.year\n",
    "        month = date.month\n",
    "        day = date.day\n",
    "\n",
    "        url = str('https://www.ngdc.noaa.gov/geomag-web/calculators/calculateIgrfwmm?'+\n",
    "              'lat1='+str(lat)+'&lon1='+str(lon)+\n",
    "              '&startYear='+str(year)+'&endYear='+str(year)+\n",
    "              '&startMonth='+str(month)+'&endMonth='+str(month)+\n",
    "              '&startDay='+str(day)+'&endDay='+str(day)+\n",
    "              '&resultFormat=csv')\n",
    "\n",
    "        import urllib\n",
    "        magdata = urllib.request.urlopen(url)\n",
    "        string = 'empty'\n",
    "        while not not string:\n",
    "            out = magdata.readline().decode(\"utf-8\")\n",
    "            if not out:\n",
    "                break\n",
    "            string = out\n",
    "        target = float(string.split(',')[4])\n",
    "        nT2milligauss = 10**-9 * 10000 * 1000 # To tesla, then to gauss then to millgauss\n",
    "        print('Target = '+str(target*nT2milligauss))\n",
    "        return target*nT2milligauss\n",
    "    \n",
    "    target = getGeoMagStrength()\n",
    "    \n",
    "    if top_mounted:\n",
    "        sign = -1\n",
    "    else:\n",
    "        sign = 1\n",
    "    \n",
    "    MagX = ADCP['MagnetometerX']\n",
    "    MagY = sign * ADCP['MagnetometerY']\n",
    "    MagZ = sign * ADCP['MagnetometerZ']\n",
    "    \n",
    "    simple = False\n",
    "    verysimple = False\n",
    "    softonly = False\n",
    "    \n",
    "    roll = ADCP['Roll']\n",
    "    pitch = ADCP['Pitch']\n",
    "    \n",
    "    norm    = lambda x,y,z : np.sqrt(x**2 + y**2 + z**2)\n",
    "    rmsd    = lambda x,y,z : np.sqrt( np.mean( ( norm(x,y,z) - target)**2 ) )\n",
    "    \n",
    "    cosd    = lambda x : np.cos(np.deg2rad(x))\n",
    "    sind    = lambda x : np.sin(np.deg2rad(x))\n",
    "    atan2d  = lambda x,y : np.rad2deg(np.arctan2(x,y))\n",
    "    rot_x   = lambda x,y,z : x*cosd(pitch) + y*sind(roll)*sind(pitch) + z*cosd(roll)*sind(pitch)\n",
    "    rot_y   = lambda x,y,z : y*cosd(roll) - z*sind(roll)\n",
    "    wrap    = lambda x : (x+360)%360\n",
    "    heading = lambda x,y,z : wrap( atan2d(rot_x(x,y,z),rot_y(x,y,z)) - 90 )\n",
    "    \n",
    "    def calibrate(x,y,z,coeffs):\n",
    "        if simple:\n",
    "            coeffs[[1,2,3,5,6,7]] = 0\n",
    "        if verysimple:\n",
    "            coeffs[:9] = 0\n",
    "            coeffs[[0,4,8]] = 1\n",
    "        if softonly:\n",
    "            coeffs[-3:] = 0\n",
    "            \n",
    "        A = np.reshape(coeffs[:9],(3,3))\n",
    "        B = coeffs[-3:]\n",
    "        out = A @ np.array([x-B[0], y-B[1], z-B[2]])\n",
    "        return out[0,:],out[1,:],out[2,:]\n",
    "    \n",
    "    def minimisation(coeffs):\n",
    "        x,y,z = calibrate(MagX,MagY,MagZ,coeffs)\n",
    "        return rmsd(x,y,z)\n",
    "    \n",
    "    coeffs = fmin(minimisation,np.array([1,0,0,0,1,0,0,0,1,0,0,0]))\n",
    "    print(np.reshape(coeffs[:9],(3,3)))\n",
    "    print(coeffs[-3:])\n",
    "    \n",
    "    magx,magy,magz = calibrate(MagX.values, MagY.values, MagZ.values,coeffs)\n",
    "    cal_heading = heading(magx,magy,magz)\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(15,15))\n",
    "    \n",
    "    plt.subplot(411)\n",
    "    plt.plot(cal_heading - ADCP.Heading,'-k')\n",
    "    plt.plot(cal_heading - heading(MagX.values, MagY.values, MagZ.values),':y',alpha=0.4)\n",
    "    plt.plot(ADCP.Heading - heading(MagX.values, MagY.values, MagZ.values),'-r.',alpha=0.3)\n",
    "    plt.ylim([-5,5])\n",
    "    \n",
    "    plt.subplot(423)\n",
    "    plt.plot(norm(MagX.values, MagY.values, MagZ.values),'-k')\n",
    "    plt.plot(norm(magx,magy,magz),'-b')\n",
    "    plt.axhline(target)\n",
    "    \n",
    "    plt.subplot(424)\n",
    "    bins = np.linspace(500,550,100)\n",
    "    _ = plt.hist(norm(magx,magy,magz),bins, color='b', alpha=0.5)\n",
    "    _ = plt.hist(norm(MagX.values, MagY.values, MagZ.values),100, color='r', alpha=0.5)\n",
    "    \n",
    "    plt.subplot(437)\n",
    "    plt.axvline(0,color='k')\n",
    "    plt.axhline(0,color='k')\n",
    "    plt.scatter(MagX.values, MagY.values, 1, 'r')\n",
    "    plt.scatter(magx,magy, 1, 'b')\n",
    "    \n",
    "    plt.subplot(438)\n",
    "    plt.axvline(0,color='k')\n",
    "    plt.axhline(0,color='k')\n",
    "    plt.scatter(MagY.values, MagZ.values, 1, 'r')\n",
    "    plt.scatter(magy,magz, 1, 'b')\n",
    "    \n",
    "    plt.subplot(439)\n",
    "    plt.axvline(0,color='k')\n",
    "    plt.axhline(0,color='k')\n",
    "    plt.scatter(MagZ.values, MagX.values, 1, 'r')\n",
    "    plt.scatter(magz,magx, 1, 'b')\n",
    "    \n",
    "    cal_heading = cal_heading\n",
    "    mag_bias = norm(magx,magy,magz)-target\n",
    "    \n",
    "    return cal_heading\n",
    "\n",
    "\n",
    "if options['correctADCPHeading']:\n",
    "    try:\n",
    "        ADCP['Heading'] = ('time', ADCP['Heading_old'].values)\n",
    "        print('Resetting to original heading')\n",
    "    except:\n",
    "        print('First run')\n",
    "    ADCP['Heading_old'] = ('time', ADCP['Heading'].values)\n",
    "    ADCP['Heading'] = ('time', _process(ADCP).values + interp(\n",
    "            data.data['Timestamp'].values.astype('float'), data.data['Declination'], ADCP.time.values.astype('float')\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b763d922-1dc6-4f5b-81e8-739b6eb4ee13",
   "metadata": {},
   "source": [
    "## 3.3. Correct ADCP velocity data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16919f-fa38-4793-baa7-07ceaa376ad7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sound speed correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e6757-4730-448f-b5a3-a93a2933d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process(ADCP):  \n",
    "    try:\n",
    "        true_ss = interp(data.data['date_float'].values, data.data['soundspeed'], ADCP.time.values.astype('float'))\n",
    "        ADCP = ADCP.rename({'SpeedOfSound':'Raw_SpeedOfSound'})        \n",
    "        ADCP['SpeedOfSound'] = ('time',true_ss)\n",
    "        ADCP['SpeedOfSound'] = ADCP['SpeedOfSound'].interp()\n",
    "        for beam in ['1','2','3','4']:\n",
    "            # V_new = V_old * (c_new/c_old)\n",
    "            ADCP['VelocityBeam'+beam] = ADCP['VelocityBeam'+beam] * (ADCP['SpeedOfSound'] / ADCP['Raw_SpeedOfSound'])\n",
    "            plog('Corrected beam '+beam+' velocity for sound speed.')\n",
    "    except:\n",
    "        plog('Speed of sound correction has already been applied')\n",
    "        \n",
    "    return ADCP\n",
    "\n",
    "ADCP = _process(ADCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf51f7-30ae-493f-8feb-8cf228d44373",
   "metadata": {},
   "source": [
    "### Outlier and poor correlation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f76caf-db58-4b9f-a90c-908c9a734445",
   "metadata": {},
   "outputs": [],
   "source": [
    "if options['ADCP_discardFirstBin']: print(ADCP.dims); ADCP = ADCP.isel(bin = ADCP['bin'] > 0); print(ADCP.dims); plog('Discarded bin 0 from ADCP data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e949f3d-f571-4be1-b1bf-f03c317b05c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# From Tanaka:\n",
    "# the velocity was 0.5 m s-1 or less,\n",
    "# the echo intensity (or amplitude) was 75 dB or less,\n",
    "# the percent-good was 80 or greater,\n",
    "# the signal-to-noise ratio (SNR) was 20 or greater.\n",
    "\n",
    "for beam in ['1','2','3','4']:\n",
    "    C = ADCP['CorrelationBeam'+beam].values.copy()\n",
    "    C[C < options['ADCP_correlationThreshold']] = np.NaN\n",
    "    C[np.isfinite(C)] = 1\n",
    "    \n",
    "    A = ADCP['AmplitudeBeam'+beam].values.copy()\n",
    "    A[A > options['ADCP_amplitudeThreshold']] = np.NaN\n",
    "    # A[A < 40] = np.NaN\n",
    "    A[np.isfinite(A)] = 1\n",
    "    \n",
    "    V = ADCP['VelocityBeam'+beam].values.copy()\n",
    "    V[np.abs(V) > options['ADCP_velocityThreshold']] = np.NaN\n",
    "    V[np.isfinite(V)] = 1\n",
    "    \n",
    "    Sh_threshold = 3\n",
    "    Sh = np.append(ADCP['VelocityBeam'+beam].diff(dim='bin').values, np.zeros([len(ADCP['time']),1]), axis=1 ) + np.insert(ADCP['VelocityBeam'+beam].diff(dim='bin').values, 0, np.zeros([1,len(ADCP['time'])]), axis=1 )\n",
    "    #print(np.nanpercentile(Sh,[Sh_threshold, 100-Sh_threshold]))\n",
    "    Sh[Sh < np.nanpercentile(Sh,Sh_threshold)] = np.NaN\n",
    "    Sh[Sh > np.nanpercentile(Sh,100 - Sh_threshold)] = np.NaN\n",
    "    Sh[np.isfinite(Sh)] = 1\n",
    "    \n",
    "    ADCP['VelocityBeam'+beam] = ADCP['VelocityBeam'+beam]*C*A*V*Sh\n",
    "    \n",
    "    plog('Outlier removal for beam '+beam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65aca59-1937-4282-ba03-ca8a88aa8786",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Correct shear bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495dce5-1244-499f-b641-3dc69188f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining coordinate transform functions for the 4 beam ADCP configuration\n",
    "def quad_beam2xyzz_mat():\n",
    "    M11=0.6782; M12=0.0000; M13=-0.6782; M14=0.0000\n",
    "    M21=0.0000; M22=-1.1831; M23=0.0000; M24=1.1831\n",
    "    M31=0.7400; M32=0.0000; M33=0.7400; M34=0.0000\n",
    "    M41=0.0000; M42=0.5518; M43=0.0000; M44=0.5518\n",
    "    T = np.array([[M11,M12,M13,M14], [M21,M22,M23,M24], [M31,M32,M33,M34], [M41,M42,M43,M44]])\n",
    "    if not top_mounted:\n",
    "        T[1:,:] = -T[1:,:]\n",
    "    return T\n",
    "\n",
    "def quad_beam2xyzz(B1,B2,B3,B4):\n",
    "    T = quad_beam2xyzz_mat()\n",
    "    try:\n",
    "        r,c = np.shape(B1.values)\n",
    "    except:\n",
    "        c = 1; r = len(B1.values)\n",
    "    V = np.array([B1.values.flatten(),\n",
    "                  B2.values.flatten(),\n",
    "                  B3.values.flatten(),\n",
    "                  B4.values.flatten()\n",
    "                 ])\n",
    "    XYZZ = V*0\n",
    "    for col in np.arange(V.shape[1]):\n",
    "        XYZZ[:,col] = T@V[:,col]   \n",
    "    return np.reshape(XYZZ[0,:],[r,c]),np.reshape(XYZZ[1,:],[r,c]),np.reshape(XYZZ[2,:],[r,c]),np.reshape(XYZZ[3,:],[r,c])\n",
    "\n",
    "def quad_xyzz2beam(X,Y,Z,ZZ):\n",
    "    T = np.linalg.inv(quad_beam2xyzz_mat())\n",
    "    r,c = np.shape(X.values)\n",
    "    XYZZ = np.array([X.values.flatten(),\n",
    "                  Y.values.flatten(),\n",
    "                  Z.values.flatten(),\n",
    "                  ZZ.values.flatten()\n",
    "                 ])\n",
    "    V = XYZZ*0\n",
    "    for col in np.arange(XYZZ.shape[1]):\n",
    "        V[:,col] = T@XYZZ[:,col]   \n",
    "    return np.reshape(V[0,:],[r,c]),np.reshape(V[1,:],[r,c]),np.reshape(V[2,:],[r,c]),np.reshape(V[3,:],[r,c])\n",
    "\n",
    "def do_xyzz2beam(ADCP):\n",
    "    V = quad_xyzz2beam(ADCP['X4'],ADCP['Y4'],ADCP['Z4'],ADCP['ZZ4'])\n",
    "    ADCP['VelocityBeam1'] = (['time','bin'], V[0])\n",
    "    ADCP['VelocityBeam2'] = (['time','bin'], V[1])\n",
    "    ADCP['VelocityBeam3'] = (['time','bin'], V[2])\n",
    "    ADCP['VelocityBeam4'] = (['time','bin'], V[3])\n",
    "    return ADCP\n",
    "    \n",
    "def do_beam2xyzz(ADCP):\n",
    "    XYZZ = quad_beam2xyzz(ADCP['VelocityBeam1'],ADCP['VelocityBeam2'],ADCP['VelocityBeam3'],ADCP['VelocityBeam4'])\n",
    "    ADCP['X4'] = (['time','bin'], XYZZ[0])\n",
    "    ADCP['Y4'] = (['time','bin'], XYZZ[1])\n",
    "    ADCP['Z4'] = (['time','bin'], XYZZ[2])\n",
    "    ADCP['ZZ4'] = (['time','bin'], XYZZ[3])\n",
    "    return ADCP\n",
    "\n",
    "def plotit():\n",
    "    plt.figure(figsize=(7,3))\n",
    "    ADCP['X4'].diff(dim='bin').mean(dim='time').plot()\n",
    "    ADCP['Y4'].diff(dim='bin').mean(dim='time').plot()\n",
    "    ADCP['Z4'].diff(dim='bin').mean(dim='time').plot()\n",
    "    ADCP['ZZ4'].diff(dim='bin').mean(dim='time').plot()\n",
    "    plt.legend(('X','Y','Z','ZZ'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10615c-17b2-49e0-9d20-ad916ce61c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shear_correction(var,correct=True):\n",
    "    def get_correction_array(row):\n",
    "        ### SEPARATION CRITERIA\n",
    "        spd_thr_water = np.sqrt(ADCP['X4']**2 + ADCP['Y4']**2 + ((ADCP['Z4']+ADCP['ZZ4'])/2)**2)\n",
    "\n",
    "        spd = spd_thr_water.values[:,0] #.values[:,5] #.mean('bin')\n",
    "\n",
    "        range_interval = 0.01\n",
    "        full_range = np.arange(0.2,0.5,range_interval)   # OMAN BEST: np.arange(0.2,0.3,range_interval)\n",
    "        cmaps = np.arange(len(full_range))/len(full_range)\n",
    "\n",
    "        ### WHAT TO PLOT\n",
    "        variable = ADCP[var]\n",
    "        _gd = (ADCP['Depth'] > 5)\n",
    "\n",
    "        ### MAKE FIGURE\n",
    "        colormap = cmo.speed\n",
    "        alpha = 30/len(full_range)\n",
    "        if alpha > 1.:\n",
    "            alpha=0.5\n",
    "\n",
    "        plt.subplot(2,3,1+row)\n",
    "        sz = plt.hist(spd, bins = np.append(full_range, np.max(full_range)+range_interval)-(range_interval/2))[0]\n",
    "        sz = sz/np.max(sz) * 50\n",
    "\n",
    "        plt.subplot(2,3,2+row)\n",
    "        x = []; y = []; c = []; s = []\n",
    "        for idx,range_level in enumerate(full_range):\n",
    "            color = colormap(cmaps[idx])\n",
    "            ind = (np.abs(spd-range_level) < (range_interval/2)) & _gd\n",
    "            arr = variable.isel(time=ind).mean('time').values\n",
    "            plt.plot(arr, color=color, alpha=alpha)\n",
    "\n",
    "            x.append(np.arange(len(arr)))\n",
    "            y.append(arr)\n",
    "            c.append(arr*0 + range_level)\n",
    "            s.append(arr*0 + sz[idx])\n",
    "\n",
    "        plt.plot(variable.isel(time=(spd > full_range[0]) & (spd < full_range[-1])).mean('time').values, color='r', linewidth=4)\n",
    "        plt.scatter(x,y,s,c, cmap=colormap)\n",
    "        plt.colorbar()\n",
    "        plt.grid('on')\n",
    "\n",
    "        plt.subplot(2,3,3+row)\n",
    "        x = []; y = []; c = []; s = []\n",
    "        for idx,range_level in enumerate(full_range):\n",
    "            color = colormap(cmaps[idx])\n",
    "            ind = (np.abs(spd-range_level) < (range_interval/2)) & _gd\n",
    "            arr = variable.isel(time=ind).diff('bin').mean('time').values\n",
    "            plt.plot(arr, color=color, alpha=alpha)\n",
    "\n",
    "            x.append(np.arange(len(arr)))\n",
    "            y.append(arr)\n",
    "            c.append(arr*0 + range_level)\n",
    "            s.append(arr*0 + sz[idx])\n",
    "\n",
    "        plt.plot(variable.isel(time=(spd > full_range[0]) & (spd < full_range[-1])).diff('bin').mean('time').values, color='r', linewidth=4)\n",
    "        plt.scatter(x,y,s,c, cmap=colormap)\n",
    "        plt.colorbar()\n",
    "        plt.axhline(0, color='k')\n",
    "        plt.grid('on')\n",
    "        plt.ylim(np.array([-1,1])*0.001)\n",
    "\n",
    "        \n",
    "        ref = np.cumsum(np.insert(variable.isel(time=(spd > full_range[0]) & (spd < full_range[-1])).diff('bin').mean('time').values,0,0))\n",
    "        ref = ref - np.nanmean(ref)\n",
    "        \n",
    "        return ref\n",
    "    \n",
    "    plt.figure(figsize=(20,6))\n",
    "    \n",
    "    if correct:\n",
    "        ADCP[var] = ADCP[var] - get_correction_array(0)\n",
    "        _ = get_correction_array(3)\n",
    "        plog('Corrected '+var)\n",
    "    else:\n",
    "        _ = get_correction_array(0)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "ADCP = do_beam2xyzz(ADCP)\n",
    "plotit()\n",
    "\n",
    "if options['correctZZshear']: ADCP = do_beam2xyzz(ADCP); shear_correction('ZZ4'); ADCP = do_xyzz2beam(ADCP);\n",
    "if options['correctZshear']: ADCP = do_beam2xyzz(ADCP); shear_correction('Z4'); ADCP = do_xyzz2beam(ADCP);\n",
    "if options['correctYshear']: ADCP = do_beam2xyzz(ADCP); shear_correction('Y4'); ADCP = do_xyzz2beam(ADCP);\n",
    "if options['correctXshear']: ADCP = do_beam2xyzz(ADCP); shear_correction('X4'); ADCP = do_xyzz2beam(ADCP);\n",
    "\n",
    "if options['correctZZshear'] or options['correctZshear'] or options['correctYshear'] or options['correctXshear']: plotit();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7e6f04-2cf9-4d76-826b-53de18cdfb56",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pitching motion correction (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a0d97-e47e-4c85-82f6-658f802c07f8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def ADCP_rotation_correction():\n",
    "#     ADCP['dPitch_dt'] = (['time'], np.gradient(np.deg2rad(ADCP.Pitch.values),ADCP.time.values.astype('float')/(10**9)))\n",
    "#     dx=0.4\n",
    "#     dz=0.125\n",
    "#     a=47.5\n",
    "#     b=25\n",
    "#     ADCP['VelocityBeam1'] = ADCP['VelocityBeam1'] + ADCP['dPitch_dt']*(-dz * np.sin(np.deg2rad(a)) + dx * np.cos(np.deg2rad(a)))\n",
    "#     ADCP['VelocityBeam3'] = ADCP['VelocityBeam3'] + ADCP['dPitch_dt']*( dz * np.sin(np.deg2rad(a)) + dx * np.cos(np.deg2rad(a)))\n",
    "#     ADCP['VelocityBeam2'] = ADCP['VelocityBeam2'] + ADCP['dPitch_dt']*( dx * np.cos(np.deg2rad(b)) )\n",
    "#     ADCP['VelocityBeam4'] = ADCP['VelocityBeam4'] + ADCP['dPitch_dt']*( dx * np.cos(np.deg2rad(b)) )\n",
    "\n",
    "# # ADCP_rotation_correction()\n",
    "# ### NOT RUNNING AS PROBABLY CODED FOR UPWARD FACING ADCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca1e56-20ae-4872-8388-1338d3bc6a8c",
   "metadata": {},
   "source": [
    "## 3.4. Correct ADCP acoustic backscatter data (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939e849-6ddf-46b4-8ede-167082eada50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372110cc-6687-4350-be9e-54a9c03a10c1",
   "metadata": {},
   "source": [
    "## 3.5. Remap 3-beam configuration onto isobars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f8993-34f7-4157-aafe-3328840f3d10",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## This is to avoid shear smearing because of tilted ADCP\n",
    "def regridADCPdata(ADCP, bin_size, blanking_distance, depth_offsets=None):   \n",
    "    \n",
    "    ## FN: calculate isobar offsets relative to glider depth for each ping\n",
    "    def calc_ideal_depth_offsets(bin_size, blanking_distance):\n",
    "        if top_mounted:\n",
    "            direction = 1\n",
    "        else:\n",
    "            direction = -1\n",
    "        threshold = 20\n",
    "        means = [np.nanmean(ADCP['CorrelationBeam'+str(x)],axis=0) for x in [1,2,3,4]]\n",
    "        stds = [np.nanstd(ADCP['CorrelationBeam'+str(x)],axis=0) for x in [1,2,3,4]]\n",
    "\n",
    "        max_bin = np.argmin(abs(np.nanmean([means[x] for x in range(4)],axis=0)  - threshold))\n",
    "        max_distance = blanking_distance + max_bin*bin_size + 0.5*bin_size\n",
    "\n",
    "        plt.close('all')\n",
    "        plt.figure(figsize=(15,7))\n",
    "        [plt.plot(ADCP['Correlation Range'].values,means[x],'-k') for x in range(4)]\n",
    "        [plt.plot(ADCP['Correlation Range'].values,means[x]+stds[x],':r') for x in range(4)]\n",
    "        [plt.plot(ADCP['Correlation Range'].values,means[x]-stds[x],':r') for x in range(4)]\n",
    "        plt.axvline(max_bin,color='g')\n",
    "        plt.title('Bin correlations')\n",
    "\n",
    "        return np.arange(blanking_distance + bin_size/2, max_distance+bin_size, bin_size/2)*direction\n",
    "\n",
    "    ## Calculate desired interpolation depth offsets\n",
    "    if depth_offsets is None:\n",
    "        depth_offsets = calc_ideal_depth_offsets(bin_size, blanking_distance)\n",
    "        \n",
    "    print('Using the following depth offsets:')\n",
    "    print(depth_offsets)\n",
    "    print(' ')\n",
    "    print('Running gridding on all 4 beams:')\n",
    "    \n",
    "    ## Extract to np array for speed\n",
    "    adcp_depth = ADCP['Depth'].values\n",
    "        \n",
    "    for beam in ['1','2','3','4']:\n",
    "        plog('Calculating beam '+beam)\n",
    "        def interp1d_np(x,y):\n",
    "            _gd = np.isfinite(y)\n",
    "            if np.count_nonzero(_gd) > 1:\n",
    "                xi = interp1d(x[_gd], y[_gd], bounds_error=False, fill_value=np.NaN)(depth_offsets)\n",
    "            else:\n",
    "                xi = depth_offsets * np.NaN\n",
    "            return xi\n",
    "        \n",
    "        ADCP.load()\n",
    "        ADCP['V'+beam] = xr.apply_ufunc(\n",
    "            interp1d_np,\n",
    "            ADCP['Depth']-ADCP['D'+beam],\n",
    "            ADCP['VelocityBeam'+beam],\n",
    "            input_core_dims=[['bin'],['bin']],\n",
    "            output_core_dims=[['gridded_bin']],\n",
    "            exclude_dims=set((\"bin\",)),\n",
    "            vectorize=True,\n",
    "            output_sizes={'gridded_bin': len(depth_offsets)},\n",
    "        )        \n",
    "        \n",
    "    ADCP = ADCP.assign_coords({'depth_offset':(['gridded_bin'], depth_offsets)})\n",
    "    ADCP = ADCP.assign_coords({'bin_depth':(['time','gridded_bin'], \n",
    "                                     np.tile(ADCP['Depth'].values.astype('float'), (len(ADCP.gridded_bin), 1)).T\n",
    "                                     - np.tile(depth_offsets, (len(ADCP.time), 1))\n",
    "                                    )})\n",
    "    \n",
    "    ## Discard everything that wasn't gridded\n",
    "    ADCP = ADCP.drop(labels=['D1','D2','D3','D4',\n",
    "                             'CorrelationBeam1','CorrelationBeam2','CorrelationBeam3','CorrelationBeam4',\n",
    "                             'VelocityBeam1','VelocityBeam2','VelocityBeam3','VelocityBeam4',\n",
    "                             'AmplitudeBeam1','AmplitudeBeam2','AmplitudeBeam3','AmplitudeBeam4'])\n",
    "    return ADCP\n",
    "\n",
    "ADCP = regridADCPdata(ADCP, bin_size, blanking_distance)\n",
    "# ADCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5e462-a7cf-45f8-8556-29a7bc263a99",
   "metadata": {},
   "source": [
    "## 3.6. Transform beams to XYZ and ENU velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696b9c5-ef25-4861-b62d-b8056d9ab39d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calcXYZfrom3beam():\n",
    "    def sin(x):\n",
    "        return np.sin(np.deg2rad(x))\n",
    "    def cos(x):\n",
    "        return np.cos(np.deg2rad(x))\n",
    "\n",
    "    a = 47.5 # Beam 1 and 3 angle from Z\n",
    "    b = 25 # Beam 2 and 4 angle from Z\n",
    "\n",
    "    xyz2beam_fore = np.array([\n",
    "        [sin(a),0,cos(a)],\n",
    "        [0,-sin(b),cos(b)],\n",
    "        [0,sin(b),cos(b)]\n",
    "    ])\n",
    "    xyz2beam_aft = np.array([\n",
    "        [-sin(a),0,cos(a)],\n",
    "        [0,-sin(b),cos(b)],\n",
    "        [0,sin(b),cos(b)]\n",
    "    ])\n",
    "\n",
    "    beam2xyz_fore = np.linalg.inv(xyz2beam_fore)\n",
    "    beam2xyz_aft = np.linalg.inv(xyz2beam_aft)\n",
    "\n",
    "    V_fore = beam2xyz_fore @ np.array([\n",
    "        ADCP['V1'].values.flatten(),\n",
    "        ADCP['V2'].values.flatten(),\n",
    "        ADCP['V4'].values.flatten()\n",
    "        ])\n",
    "    V_aft = beam2xyz_aft @ np.array([\n",
    "        ADCP['V3'].values.flatten(),\n",
    "        ADCP['V2'].values.flatten(),\n",
    "        ADCP['V4'].values.flatten()\n",
    "        ])\n",
    "\n",
    "    if rmsd(V_aft[1:,:]-V_fore[1:,:]) != 0:\n",
    "        plt.plot(V_aft[1:,:]-V_fore[1:,:],'-kx')\n",
    "        print(rmsd(V_aft[1:,:]-V_fore[1:,:]))\n",
    "        plog('Something is wrong - abort and investigate...')\n",
    "\n",
    "    X_fore = np.reshape( V_fore[0,:] , np.shape(ADCP['V1']) )\n",
    "    X_aft = np.reshape( V_aft[0,:] , np.shape(ADCP['V1']) )\n",
    "    \n",
    "    plt.close('all')\n",
    "    _ = plt.hist(X_fore.flatten(),np.linspace(-1,1,200),color='r',alpha=0.2)\n",
    "    _ = plt.hist(X_aft.flatten(),np.linspace(-1,1,200),color='y',alpha=0.2)\n",
    "    plt.axvline(0)\n",
    "    plt.title('Both X histograms should more or less overlap, and more importantly: be negative')\n",
    "    \n",
    "    use_aft_on_climb = ADCP['Pitch'] > 0\n",
    "    \n",
    "    X = X_fore.copy()\n",
    "    \n",
    "    if top_mounted == True:\n",
    "        print('Assuming ADCP is top mounted')\n",
    "        X[~use_aft_on_climb,:] = X_aft[~use_aft_on_climb,:]\n",
    "    else:\n",
    "        print('Assuming ADCP is bottom mounted')\n",
    "        X[use_aft_on_climb,:] = X_aft[use_aft_on_climb,:]\n",
    "    \n",
    "    \n",
    "    _ = plt.hist(X.flatten(),np.linspace(-1,1,200),color='g',alpha=0.2)\n",
    "    \n",
    "    ADCP['X'] = (['time','gridded_bin'], X )\n",
    "    ADCP['Y'] = (['time','gridded_bin'], np.reshape( V_aft[1,:] , np.shape(ADCP['V1']) ) )\n",
    "    ADCP['Z'] = (['time','gridded_bin'], np.reshape( V_aft[2,:] , np.shape(ADCP['V1']) ) )\n",
    "    \n",
    "    plog('Calculating X,Y,Z from isobaric 3-beam measurements.')\n",
    "    \n",
    "    \n",
    "calcXYZfrom3beam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659aae6b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calcENUfromXYZ():\n",
    "    def M_xyz2enu(heading,pitch,roll):\n",
    "        hh = np.pi*(heading-90)/180\n",
    "        pp = np.pi*pitch/180\n",
    "        rr = np.pi*roll/180\n",
    "\n",
    "        _H = np.array([\n",
    "            [np.cos(hh),np.sin(hh),0], \n",
    "            [-np.sin(hh),np.cos(hh),0], \n",
    "            [0,0,1]\n",
    "        ])\n",
    "        _P = np.array([\n",
    "            [np.cos(pp), 0, -np.sin(pp)] ,\n",
    "            [0, 1, 0] , \n",
    "            [ np.sin(pp), 0, np.cos(pp)]\n",
    "        ])\n",
    "        _R = np.array([\n",
    "            [1, 0, 0] ,\n",
    "            [0, np.cos(rr), -np.sin(rr)] , \n",
    "            [0, np.sin(rr), np.cos(rr)]\n",
    "        ])\n",
    "\n",
    "        _M = _H@_P@_R\n",
    "        return _M\n",
    "\n",
    "    H = ADCP['Heading'].values\n",
    "    P = ADCP['Pitch'].values\n",
    "    R = ADCP['Roll'].values\n",
    "\n",
    "    if top_mounted:\n",
    "        direction = 1\n",
    "    else:\n",
    "        direction = -1\n",
    "        \n",
    "    E = ADCP['X'].values.copy()\n",
    "    N = ADCP['Y'].values.copy()*direction\n",
    "    U = ADCP['Z'].values.copy()*direction\n",
    "\n",
    "    r,c = np.shape(E)\n",
    "    \n",
    "    for i in tqdm(range(r)):\n",
    "        XYZ2ENU = M_xyz2enu(H[i],P[i],R[i])\n",
    "        for j in range(c):\n",
    "            E[i,j], N[i,j], U[i,j] = XYZ2ENU @ [E[i,j], N[i,j], U[i,j]]   \n",
    "    \n",
    "\n",
    "    ADCP['E'] = (['time','gridded_bin'], E )\n",
    "    ADCP['N'] = (['time','gridded_bin'], N )\n",
    "    ADCP['U'] = (['time','gridded_bin'], U )\n",
    "    \n",
    "    plog('Converted from XYZ to ENU')\n",
    "\n",
    "calcENUfromXYZ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd5e38",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def verify():\n",
    "    plt.figure()\n",
    "\n",
    "    PD = (ADCP['Pitch'].values < 0) & (ADCP['Depth'].values > 20)\n",
    "    PU = (ADCP['Pitch'].values > 0) & (ADCP['Depth'].values > 20)\n",
    "\n",
    "    print(np.count_nonzero(PD),np.count_nonzero(PU))\n",
    "\n",
    "    plt.subplot(511)\n",
    "    _ = plt.hist(ADCP.isel(time=PD)['X'].values.flatten(),np.linspace(-1,1,200),color='r')\n",
    "    _ = plt.hist(ADCP.isel(time=PU)['X'].values.flatten(),np.linspace(-1,1,200),color='b')\n",
    "    plt.title('Glider moving forward so expect X negative')\n",
    "\n",
    "    plt.subplot(513)\n",
    "    _ = plt.hist(ADCP.isel(time=PD)['U'].values.flatten(),np.linspace(-1,1,200),color='r')\n",
    "    plt.title('Glider diving so expect U positive')\n",
    "\n",
    "    plt.subplot(515)\n",
    "    _ = plt.hist(ADCP.isel(time=PU)['U'].values.flatten(),np.linspace(-1,1,200),color='b')\n",
    "    plt.title('Glider climbing so expect U negative')\n",
    "    \n",
    "verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a4089-ee70-4d2f-a50b-6e4d934764fe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _verify():\n",
    "\n",
    "    _gd = (ADCP['Pressure'].values > 10)\n",
    "    \n",
    "    PD = (ADCP.isel(time=_gd)['Pitch'].values < 0) & (ADCP.isel(time=_gd)['Depth'].values > 20)\n",
    "    PU = (ADCP.isel(time=_gd)['Pitch'].values > 0) & (ADCP.isel(time=_gd)['Depth'].values > 20)\n",
    "\n",
    "    T = ADCP.isel(time=_gd)['time']\n",
    "    D = ADCP.isel(time=_gd)['Depth']\n",
    "    R = ADCP.isel(time=_gd)['Roll']\n",
    "    U = ADCP.isel(time=_gd)['U'].mean(dim='gridded_bin').values.flatten()# * 1.009\n",
    "    dP = np.gradient(ADCP.isel(time=_gd)['Depth'].values, ADCP.isel(time=_gd)['time'].astype('float')/1e9)\n",
    "    \n",
    "    bins = np.linspace(-1,1,100)*0.2\n",
    "    \n",
    "    plt.figure(figsize=(20,7))\n",
    "    plt.subplot(221)\n",
    "    _ = plt.hist(U,bins,color='b',alpha=0.5)\n",
    "    _ = plt.hist(dP,bins,color='r',alpha=0.5)\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    _ = plt.hist((dP-U)[PD],bins/10,color='b',alpha=0.5)\n",
    "    _ = plt.hist((dP-U)[PU],bins/10,color='r',alpha=0.5)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.scatter(T,D,5,dP-U, cmap=cmo.balance)\n",
    "    plt.colorbar()\n",
    "    plt.clim([bins[0]/10,bins[-1]/10])\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    \n",
    "_verify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c20de-d48e-4f83-9b9a-f07f0be20b36",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.7. Calculate shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab28ffee",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ADCP['Sh_E'] = (['time','gridded_bin'],\n",
    "                  ADCP['E'].differentiate('gridded_bin').values\n",
    "                 )\n",
    "ADCP['Sh_N'] = (['time','gridded_bin'],\n",
    "                  ADCP['N'].differentiate('gridded_bin').values\n",
    "                 )\n",
    "ADCP['Sh_U'] = (['time','gridded_bin'],\n",
    "                  ADCP['U'].differentiate('gridded_bin').values\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69808fac",
   "metadata": {},
   "source": [
    "# V. Flight model regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85637595",
   "metadata": {},
   "source": [
    "## 5.1. Regress model and extract flight speeds\n",
    "\n",
    "Should I lowpass filter velocities with a filter freq equal to N?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f9526",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def flight_model():    \n",
    "    # time, sal, temp_ext, temp_int, pres_ext, pres_int, lon, lat, ballast, pitch, profile, navresource, tau, adcp_speed, **param\n",
    "    flight = sx.SemiDynamicModel(\n",
    "           data.data.Timestamp, \n",
    "           data.data.salinity.interpolate('index').fillna(method='bfill').values, \n",
    "           data.data.temperature.interpolate('index').fillna(method='bfill').values, \n",
    "           data.data.Temperature.interpolate('index').fillna(method='bfill').values, \n",
    "           data.data.LEGATO_PRESSURE.interpolate('index').fillna(method='bfill').values, \n",
    "           data.data.Pa.interpolate('index').fillna(method='bfill').values, \n",
    "           data.data.longitude.interpolate('index').fillna(method='bfill').values, \n",
    "           data.data.latitude.interpolate('index').fillna(method='bfill').values, \n",
    "           data.data.BallastPos.interpolate('index').fillna(method='bfill').values, \n",
    "           data.data.Pitch.interpolate('index').fillna(method='bfill').values, \n",
    "           data.data.profileNum.interpolate('nearest').fillna(method='bfill').values,\n",
    "           data.data.NAV_RESOURCE.interpolate('nearest').fillna(method='bfill').values,\n",
    "           0.5,\n",
    "           interp(ADCP.time.values.astype('float'), ADCP.GliderSpeed, data.data.Timestamp.values.astype('float')),\n",
    "           mass=60.772, vol0=0.059077990061655435, \n",
    "           Cd_0=0.068891783927366, Cd_1=0.8210920513705997, Cl=1.9140152638563785, \n",
    "           comp_p=4.4e-06, comp_t=6.973743090064374e-05, \n",
    "           lag_t=0.55, SSStau=13)\n",
    "    \n",
    "    #flight.regression_parameters = ('Cd_0','Cd_1','Cl','vol0','comp_t', 'SSStau') # 'Cd_0','Cd_1','Cl','SSStau',     \n",
    "    flight.regression_parameters = ('Cd_0','Cd_1','Cl','vol0','comp_p','comp_t') # 'Cd_0','Cd_1','Cl','SSStau', \n",
    "    flight._valid[data.data.LEGATO_PRESSURE < 5] = False\n",
    "    # flight._valid[data.data.LEGATO_PRESSURE > 100] = False\n",
    "    flight.regress()\n",
    "\n",
    "    data.data['alpha'] = flight.alpha\n",
    "    data.data['speed'] = flight.speed\n",
    "    data.data['speed_vert'] = flight.speed_vert\n",
    "    data.data['speed_horz'] = flight.speed_horz\n",
    "    data.data['w_H2O'] = flight.w_H2O\n",
    "\n",
    "    return flight\n",
    "\n",
    "ADCP['GliderSpeed'] = (\n",
    "    'time',\n",
    "    np.sqrt(ADCP['X4']**2 + ADCP['Y4']**2 + ((ADCP['Z4']+ADCP['ZZ4'])/2)**2).isel(bin=np.arange(3)).mean('bin').interp().values\n",
    "    )\n",
    "\n",
    "flight = flight_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942d5de-a4df-4183-9b38-c5b74f57ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "V,XI,YI = sx.grid2d(\n",
    "    data.data.profileNum.values,\n",
    "    data.data.LEGATO_PRESSURE.values, \n",
    "    flight.w_H2O, \n",
    "    xi=xaxis, yi=yaxis, fn='mean')\n",
    "print(np.shape(V))\n",
    "\n",
    "if np.remainder(np.shape(V)[1],2) == 1:\n",
    "    V_old = V.copy\n",
    "    V = V[:,:-1]\n",
    "    print(np.shape(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efdd742-bad3-4d6f-8247-be7b3bfd1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(flight):\n",
    "    plt.figure(figsize=(20,15))\n",
    "\n",
    "    mask = flight._valid # & (np.sign(flight.dZdt) == -1)\n",
    "    \n",
    "    plt.subplot(331)\n",
    "    V,XI,YI = sx.grid2d(\n",
    "        data.data.profileNum[mask].values,\n",
    "        data.data.LEGATO_PRESSURE[mask].values, \n",
    "        flight.w_H2O[mask], \n",
    "        xi=xaxis, yi=yaxis, fn='mean')\n",
    "    DZ,XI,YI = sx.grid2d(\n",
    "        data.data.profileNum[mask].values,\n",
    "        data.data.LEGATO_PRESSURE[mask].values, \n",
    "        flight.dZdt[mask], \n",
    "        xi=xaxis, yi=yaxis, fn='mean')\n",
    "    SV,XI,YI = sx.grid2d(\n",
    "        data.data.profileNum[mask].values,\n",
    "        data.data.LEGATO_PRESSURE[mask].values, \n",
    "        flight.speed_vert[mask], \n",
    "        xi=xaxis, yi=yaxis, fn='mean')\n",
    "    \n",
    "    plt.pcolormesh(XI,YI,V,cmap=cmo.balance,shading='auto')\n",
    "    plt.colorbar()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.clim([-0.02,0.02])\n",
    "    plt.title('W H2O')\n",
    "    \n",
    "    plt.subplot(332)\n",
    "    if np.remainder(np.shape(V)[1],2) == 1:\n",
    "        plt.pcolormesh(XI[:,:-1:2]/2,YI[:,:-1:2],V[:,:-1:2]-V[:,1::2],cmap=cmo.balance,shading='auto')\n",
    "    else:\n",
    "        plt.pcolormesh(XI[:,::2]/2,YI[:,::2],V[:,::2]-V[:,1::2],cmap=cmo.balance,shading='auto')\n",
    "    plt.colorbar()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.clim([-0.02,0.02])\n",
    "    plt.title('Up-Down (W H2O)')\n",
    "    \n",
    "    plt.subplot(333)\n",
    "    plt.axvline(0)\n",
    "    plt.plot(np.nanmean(V[:,::2],axis=1),yaxis,'-g')\n",
    "    plt.plot(np.nanmean(V[:,1::2],axis=1),yaxis,':g')\n",
    "    plt.plot(np.nanmean(DZ[:,::2],axis=1),yaxis,'-b')\n",
    "    plt.plot(np.nanmean(DZ[:,1::2],axis=1),yaxis,'-b')\n",
    "    plt.plot(np.nanmean(SV[:,::2],axis=1),yaxis,':r')\n",
    "    plt.plot(np.nanmean(SV[:,1::2],axis=1),yaxis,':r')\n",
    "    plt.xlim([-0.2, 0.2])\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.subplot(334)\n",
    "    _ = plt.hist(flight.w_H2O.flatten(), np.linspace(-0.1,0.1,1000),alpha=0.2)\n",
    "    _ = plt.hist(flight.w_H2O[mask].flatten(), np.linspace(-0.1,0.1,1000),alpha=0.2)\n",
    "    plt.axvline(0)\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    \n",
    "    plt.subplot(335)\n",
    "    _ = plt.hist(flight.speed[mask] - flight.speed_through_water[mask], np.linspace(-0.1,0.1,1000),alpha=0.2)\n",
    "    _ = plt.hist(flight.speed - flight.speed_through_water, np.linspace(-0.1,0.1,1000),alpha=0.2)\n",
    "    plt.axvline(0)\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.subplot(336)\n",
    "    V,XI,YI = sx.grid2d(\n",
    "        data.data.profileNum[mask].values,\n",
    "        data.data.LEGATO_PRESSURE[mask].values, \n",
    "        flight._valid[mask], \n",
    "        xi=xaxis, yi=yaxis, fn='sum')\n",
    "    plt.pcolormesh(XI,YI,V,cmap=cmo.dense,shading='auto')\n",
    "    plt.colorbar()\n",
    "    plt.gca().invert_yaxis()\n",
    "    # plt.clim([-0.02,0.02])\n",
    "    plt.title('Num valid points in regression')\n",
    "    \n",
    "    plt.subplot(337)\n",
    "    V,XI,YI = sx.grid2d(\n",
    "        data.data.profileNum[mask].values,\n",
    "        data.data.LEGATO_PRESSURE[mask].values, \n",
    "        flight.dZdt[mask], \n",
    "        xi=xaxis, yi=yaxis, fn='mean')\n",
    "    plt.pcolormesh(XI,YI,V,cmap=cmo.dense,shading='auto')\n",
    "    plt.colorbar()\n",
    "    plt.gca().invert_yaxis()\n",
    "    # plt.clim([-0.02,0.02])\n",
    "    plt.title('Vert speed')\n",
    "    \n",
    "    plt.subplot(338)\n",
    "    V,XI,YI = sx.grid2d(\n",
    "        data.data.profileNum[mask].values,\n",
    "        data.data.LEGATO_PRESSURE[mask].values, \n",
    "        np.rad2deg(flight.pitch[mask]), \n",
    "        xi=xaxis, yi=yaxis, fn='mean')\n",
    "    plt.pcolormesh(XI,YI,V,cmap=cmo.dense,shading='auto')\n",
    "    plt.colorbar()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.clim([-30,0])\n",
    "    plt.title('Pitch')\n",
    "    \n",
    "    \n",
    "    plt.subplot(339)\n",
    "    V,XI,YI = sx.grid2d(\n",
    "        data.data.profileNum.values,\n",
    "        data.data.LEGATO_PRESSURE.values, \n",
    "        flight.w_H2O, \n",
    "        xi=1, yi=np.arange(0,1000,5), fn='mean')\n",
    "    SA,_,_ = sx.grid2d(\n",
    "        data.data.profileNum.values,\n",
    "        data.data.LEGATO_PRESSURE.values, \n",
    "        data.data.sa, \n",
    "        xi=1, yi=np.arange(-2.5,1002.5,5), fn='mean')\n",
    "    CT,_,YI2 =sx.grid2d(\n",
    "        data.data.profileNum.values,\n",
    "        data.data.LEGATO_PRESSURE.values, \n",
    "        data.data.ct, \n",
    "        xi=1, yi=np.arange(-2.5,1002.5,5), fn='mean')\n",
    "    N2,_ = gsw.Nsquared(SA,CT,YI2)\n",
    "    \n",
    "    plt.scatter(N2.flatten(),V.flatten()**2,2,'k',alpha=0.3)\n",
    "    plt.xlim([0,5e-4])\n",
    "    plt.ylim([0,5e-4])\n",
    "    \n",
    "verify(flight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222a550",
   "metadata": {},
   "source": [
    "## 5.2. Calculate dive-averaged current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08c01c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _getDAC(data):\n",
    "    ## Calculate full x-y dead reckoning during each dive\n",
    "    def reset_transport_at_GPS(arr):\n",
    "        ffill = lambda arr: pd.DataFrame(arr).fillna(method='ffill').values.flatten()\n",
    "        ref = np.zeros(np.shape(arr)) * np.NaN\n",
    "        ref[_gps] = arr[_gps]\n",
    "        return (arr - ffill(ref))\n",
    "    \n",
    "    _gps = (data.data.DeadReckoning.values < 1) & (data.data.NAV_RESOURCE.values == 116)\n",
    "    \n",
    "    t = data.data.date_float.values * 1e-9\n",
    "    heading = interp(ADCP['time'].values.astype('float'), ADCP['Heading'].values, data.data.date_float.values)\n",
    "    # heading = (data.data['Heading'] + data.data['Declination']).interpolate('linear')\n",
    "    vg_e = np.nan_to_num(data.data['speed_horz'] *np.sin( heading * np.pi/180 ))\n",
    "    vg_n = np.nan_to_num(data.data['speed_horz'] *np.cos( heading * np.pi/180 ))\n",
    "\n",
    "    de = np.cumsum(np.append(0, vg_e[1:] * np.diff(t)))\n",
    "    dn = np.cumsum(np.append(0, vg_n[1:] * np.diff(t)))\n",
    "\n",
    "    de = reset_transport_at_GPS(de)\n",
    "    dn = reset_transport_at_GPS(dn)\n",
    "\n",
    "    ## Calculate on per dive basis\n",
    "    dnum = np.unique(data.data.diveNum.values)\n",
    "    sidx = np.zeros(np.shape(dnum))*np.NaN\n",
    "    didx = np.zeros(np.shape(dnum))*np.NaN\n",
    "    \n",
    "    for idx,dx in enumerate(dnum):\n",
    "        try:\n",
    "            sidx[idx] = np.flatnonzero((data.data.diveNum.values == dx) & _gps)[0]\n",
    "            didx[idx] = np.flatnonzero((data.data.diveNum.values == dx) & _gps)[-1]\n",
    "        except:\n",
    "            continue\n",
    "                        \n",
    "    _gd = np.isfinite(sidx+didx+dnum)\n",
    "    dnum = dnum[_gd]\n",
    "    sidx = sidx[_gd]\n",
    "    didx = didx[_gd]\n",
    "    \n",
    "    sidx = sidx.astype(int)\n",
    "    didx = didx.astype(int)\n",
    "   \n",
    "    surf_lat = data.data.latitude.values[sidx]\n",
    "    surf_lon = data.data.longitude[sidx]\n",
    "    surf_time = t[sidx]\n",
    "\n",
    "    dive_lat = data.data.latitude[didx]\n",
    "    dive_lon = data.data.longitude[didx]\n",
    "    dive_time = t[didx]\n",
    "\n",
    "    dr_e = np.zeros(np.shape(dnum)) * np.NaN\n",
    "    dr_n = np.zeros(np.shape(dnum)) * np.NaN\n",
    "    gps_e = np.zeros(np.shape(dnum)) * np.NaN\n",
    "    gps_n = np.zeros(np.shape(dnum)) * np.NaN\n",
    "    dt = np.zeros(np.shape(dnum)) * np.NaN\n",
    "    meant = np.zeros(np.shape(dnum)) * np.NaN\n",
    "\n",
    "    lon2m = lambda x,y : gsw.distance([x,x+1],[y,y])\n",
    "    lat2m = lambda x,y : gsw.distance([x,x],[y,y+1])\n",
    "    \n",
    "    for idx,dx in enumerate(dnum):\n",
    "        try:\n",
    "            dr_e[idx] = de[ sidx[idx+1]-1 ]\n",
    "            dr_n[idx] = dn[ sidx[idx+1]-1 ]\n",
    "            gps_e[idx] = (surf_lon[idx+1] - dive_lon[idx]) * lon2m(dive_lon[idx],dive_lat[idx])\n",
    "            gps_n[idx] = (surf_lat[idx+1] - dive_lat[idx]) * lat2m(dive_lon[idx],dive_lat[idx])\n",
    "            dt[idx] = surf_time[idx+1] - dive_time[idx]\n",
    "            meant[idx] = (surf_time[idx+1] + dive_time[idx])/2\n",
    "        except:\n",
    "            print('No final GPS for dive '+str(dx))\n",
    "\n",
    "    dac_e = (gps_e-dr_e)/dt\n",
    "    dac_n = (gps_n-dr_n)/dt\n",
    "    \n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(pd.to_datetime(meant),dac_e,'o-r')\n",
    "    plt.plot(pd.to_datetime(meant),dac_n,'o-b')\n",
    "    plt.legend(('DAC E','DAC N'))\n",
    "\n",
    "    data.data['DAC_E'] = interp(meant, (gps_e-dr_e)/dt, t)\n",
    "    data.data['DAC_N'] = interp(meant, (gps_n-dr_n)/dt, t)\n",
    "    \n",
    "    data.data['DAC_E'] = data.data['DAC_E'].fillna(method='bfill').fillna(method='ffill')\n",
    "    data.data['DAC_N'] = data.data['DAC_N'].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "_getDAC(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b7cfd-a97c-4b04-8537-35041e274be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "E,X,Y = sx.grid2d(data.data.Timestamp.values.astype('float'), data.data.latitude, data.data.DAC_E, xi= 10**9 * 60 * 60 * 3, yi=0.01)\n",
    "\n",
    "N,X,Y = sx.grid2d(data.data.Timestamp.values.astype('float'), data.data.latitude, data.data.DAC_N, xi= 10**9 * 60 * 60 * 3, yi=0.01)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.scatter(X, Y, 100, E, cmap=cmo.balance)\n",
    "plt.colorbar()\n",
    "plt.title('East')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.scatter(X, Y, 100, N, cmap=cmo.balance)\n",
    "plt.colorbar()\n",
    "plt.title('North')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226ec008-9b4f-415e-a95f-d8280e71a1dd",
   "metadata": {},
   "source": [
    "## 5.3. Get surface drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c6bd4-4ad2-4ac2-8694-6aa13c340ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurfaceDrift():\n",
    "    _gps = (data.data.DeadReckoning.values < 1) & (data.data.NAV_RESOURCE.values == 116)\n",
    "    \n",
    "    lon2m = lambda x,y : gsw.distance([x,x+1],[y,y])\n",
    "    lat2m = lambda x,y : gsw.distance([x,x],[y,y+1])\n",
    "    \n",
    "    dnum = data.data.diveNum.values[_gps]\n",
    "    \n",
    "    lons = data.data.longitude.values[_gps]\n",
    "    lats = data.data.latitude.values[_gps]\n",
    "    \n",
    "    dlons = np.gradient(lons)\n",
    "    dlats = np.gradient(lats)\n",
    "        \n",
    "    for idx in range(len(lons)):\n",
    "        dlons[idx] = dlons[idx] * lon2m(lons[idx],lats[idx])\n",
    "        dlats[idx] = dlats[idx] * lat2m(lons[idx],lats[idx])\n",
    "    \n",
    "    times = data.data.Timestamp.values.astype('float')[_gps] / 10**9\n",
    "    dtimes = np.gradient(times)\n",
    "    \n",
    "    dE = np.full(int(np.nanmax(data.data.diveNum)), np.NaN)\n",
    "    dN = np.full(int(np.nanmax(data.data.diveNum)), np.NaN)\n",
    "    dT = np.full(int(np.nanmax(data.data.diveNum)), np.NaN)\n",
    "    \n",
    "    for idx in range(len(dE)):\n",
    "        _gd = (dtimes < 21) & (dnum == idx+1)\n",
    "        dE[idx] = np.nanmedian(dlons[_gd]/dtimes[_gd])\n",
    "        dN[idx] = np.nanmedian(dlats[_gd]/dtimes[_gd])\n",
    "        dT[idx] = np.nanmean(times[_gd])\n",
    "    \n",
    "    dT = dT * 10**9\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.subplot(211)\n",
    "    plt.plot(pd.to_datetime(dT),dE,'.-r')\n",
    "    plt.title('U')\n",
    "    plt.subplot(212)\n",
    "    plt.plot(pd.to_datetime(dT),dN,'.-r')\n",
    "    plt.title('V')\n",
    "    \n",
    "    return dE,dN,dT\n",
    "    \n",
    "    \n",
    "dE,dN,dT = getSurfaceDrift()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2b746-fcaa-47ff-8f99-1c7c5023878f",
   "metadata": {},
   "source": [
    "## 5.4. Get bottom track data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0d70b-220d-447e-8969-18ebfc5d19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process(ADCP):\n",
    "    def sin(x):\n",
    "        return np.sin(np.deg2rad(x))\n",
    "    def cos(x):\n",
    "        return np.cos(np.deg2rad(x))\n",
    "    # BT gives us speed of the glider\n",
    "    # If we subtract BT velocity from XYZ\n",
    "    # then we get speed of water\n",
    "    BT = xr.open_mfdataset(adcp_path,group='Data/AverageBT')\n",
    "\n",
    "    thresh = 12\n",
    "\n",
    "    ind = (BT['VelocityBeam1'] > -2) & (BT['VelocityBeam2'] > -2) & (BT['VelocityBeam4'] > -2)\n",
    "    ind2 = (BT['FOMBeam1'] < thresh) & (BT['FOMBeam2'] < thresh) & (BT['FOMBeam4'] < thresh)\n",
    "    BT = BT.isel(time=ind & ind2)\n",
    "    \n",
    "    full_time = ADCP['time'].values.astype('float')\n",
    "    BT_time = BT['time'].values.astype('float')\n",
    "    matching = []\n",
    "    for idx in tqdm(range(len(BT_time))):\n",
    "        matching.append( np.argmin( np.abs(BT_time[idx]-full_time) ) )\n",
    "        \n",
    "    ADCP_profile = ADCP['profileNum'].values\n",
    "    ADCP_depth = ADCP['Pressure'].values\n",
    "    for idx in range( np.nanmax(ADCP_profile).astype(int) ):\n",
    "        _gd = (ADCP_profile == idx)\n",
    "        if np.count_nonzero(_gd) == 0:\n",
    "            print('Profile '+str(idx)+' was empy')\n",
    "        else:\n",
    "            ADCP_depth[_gd] = np.nanmax(ADCP_depth[_gd])\n",
    "    ADCP_depth = ADCP_depth[matching]\n",
    "    \n",
    "    \n",
    "    _gd = (np.abs(ADCP_depth-BT['Pressure']).values < 15)\n",
    "    BT = BT.isel(time=_gd)\n",
    "    full_time = ADCP['time'].values.astype('float')\n",
    "    BT_time = BT['time'].values.astype('float')\n",
    "    matching = []\n",
    "    for idx in tqdm(range(len(BT_time))):\n",
    "        matching.append( np.argmin( np.abs(BT_time[idx]-full_time) ) )\n",
    "    \n",
    "    C_old = BT['SpeedOfSound'].values\n",
    "    C_new = ADCP['SpeedOfSound'].isel(time=matching).values\n",
    "    \n",
    "    a = 47.5 # Beam 1 and 3 angle from Z\n",
    "    b = 25 # Beam 2 and 4 angle from Z\n",
    "    xyz2beam_fore = np.array([\n",
    "        [sin(a),0,cos(a)],\n",
    "        [0,-sin(b),cos(b)],\n",
    "        [0,sin(b),cos(b)]\n",
    "    ])\n",
    "    beam2xyz_fore = np.linalg.inv(xyz2beam_fore)\n",
    "    \n",
    "    BT_X4, BT_Y4, BT_Z4 = beam2xyz_fore @ np.array([\n",
    "        BT['VelocityBeam1'] * (C_new/C_old),\n",
    "        BT['VelocityBeam2'] * (C_new/C_old),\n",
    "        BT['VelocityBeam4'] * (C_new/C_old),\n",
    "        ])\n",
    "\n",
    "    def M_xyz2enu(heading,pitch,roll):\n",
    "        hh = np.pi*(heading-90)/180\n",
    "        pp = np.pi*pitch/180\n",
    "        rr = np.pi*roll/180\n",
    "\n",
    "        _H = np.array([\n",
    "            [np.cos(hh),np.sin(hh),0], \n",
    "            [-np.sin(hh),np.cos(hh),0], \n",
    "            [0,0,1]\n",
    "        ])\n",
    "        _P = np.array([\n",
    "            [np.cos(pp), 0, -np.sin(pp)] ,\n",
    "            [0, 1, 0] , \n",
    "            [ np.sin(pp), 0, np.cos(pp)]\n",
    "        ])\n",
    "        _R = np.array([\n",
    "            [1, 0, 0] ,\n",
    "            [0, np.cos(rr), -np.sin(rr)] , \n",
    "            [0, np.sin(rr), np.cos(rr)]\n",
    "        ])\n",
    "\n",
    "        _M = _H@_P@_R\n",
    "        return _M\n",
    "\n",
    "    H = BT['Heading'].values\n",
    "    P = BT['Pitch'].values\n",
    "    R = BT['Roll'].values\n",
    "\n",
    "    BT_E = np.full_like(H,np.NaN)\n",
    "    BT_N = np.full_like(H,np.NaN)\n",
    "    BT_U = np.full_like(H,np.NaN)\n",
    "\n",
    "    if top_mounted:\n",
    "        direction = 1\n",
    "    else:\n",
    "        direction = -1\n",
    "\n",
    "    n = len(BT_X4)\n",
    "    for i in tqdm(range(n)):\n",
    "        BT_E[i], BT_N[i], BT_U[i] = M_xyz2enu(H[i],P[i],R[i]) @ [BT_X4[i], BT_Y4[i]*direction, BT_Z4[i]*direction]   \n",
    "\n",
    "    bt_e = np.full_like(full_time,np.NaN)\n",
    "    bt_e[matching] = BT_E\n",
    "    bt_n = np.full_like(full_time,np.NaN)\n",
    "    bt_n[matching] = BT_N\n",
    "    bt_u = np.full_like(full_time,np.NaN)\n",
    "    bt_u[matching] = BT_U\n",
    "\n",
    "    ADCP['BT_E'] = ('time', bt_e)\n",
    "    ADCP['BT_N'] = ('time', bt_n)\n",
    "    ADCP['BT_U'] = ('time', bt_u)\n",
    "    \n",
    "    return ADCP\n",
    "    \n",
    "ADCP = _process(ADCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8332a-e9e1-4981-ad60-185d84e3746a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.5. Reference ADCP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2e2c2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def verify():\n",
    "    x = np.arange(0,np.shape(ADCP.Sh_E.values)[0],1)\n",
    "\n",
    "    SHEm,XI,YI = sx.grid2d(\n",
    "        np.tile(ADCP.profileNum.values, (len(ADCP.gridded_bin), 1)).T[x,:].flatten(),\n",
    "        ADCP.bin_depth.values[x,:].flatten(), \n",
    "        ADCP.Sh_E.values[x,:].flatten(), \n",
    "        xi=1, yi=5, fn='mean')\n",
    "    SHEs,XI,YI = sx.grid2d(\n",
    "        np.tile(ADCP.profileNum.values, (len(ADCP.gridded_bin), 1)).T[x,:].flatten(),\n",
    "        ADCP.bin_depth.values[x,:].flatten(), \n",
    "        ADCP.Sh_E.values[x,:].flatten(), \n",
    "        xi=1, yi=5, fn='std')\n",
    "    SHEn,XI,YI = sx.grid2d(\n",
    "        np.tile(ADCP.profileNum.values, (len(ADCP.gridded_bin), 1)).T[x,:].flatten(),\n",
    "        ADCP.bin_depth.values[x,:].flatten(), \n",
    "        ADCP.Sh_E.values[x,:].flatten(), \n",
    "        xi=1, yi=5, fn='count')\n",
    "\n",
    "    plt.figure(figsize=(15,12))\n",
    "\n",
    "    plt.subplot(221)\n",
    "    plt.pcolormesh(XI,YI,SHEs/np.sqrt(SHEn))\n",
    "    plt.colorbar()\n",
    "    # plt.clim([0,300])\n",
    "    plt.ylim([0,500])\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.subplot(223)\n",
    "    plt.pcolormesh(XI,YI,SHEm,cmap=cmo.balance)\n",
    "    plt.colorbar()\n",
    "    plt.ylim([0,500])\n",
    "    plt.clim([-0.05,0.05])\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.subplot(224)\n",
    "    plt.pcolormesh(XI,YI,SHEn)\n",
    "    plt.colorbar()\n",
    "    plt.ylim([0,500])\n",
    "    # plt.clim([0,0.01])\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.subplot(222)\n",
    "    _ = plt.hist(SHEs.flatten(), np.linspace(0,0.05,100))\n",
    "    \n",
    "verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863b3b8-015e-4fcf-be5c-142525a06b0d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _verify():\n",
    "    var = ['E','N']\n",
    "    \n",
    "    plt.figure(figsize=(20,15))\n",
    "    \n",
    "    days = np.unique(data.data.Timestamp.round('D'))\n",
    "    for pstep in range(len(var)):\n",
    "        \n",
    "        letter = var[pstep]\n",
    "        # Grid shear to average out sensor + zooplankton noise\n",
    "        Sh,XI,YI = sx.grid2d(\n",
    "            np.tile(ADCP.profileNum.values, (len(ADCP.gridded_bin), 1)).T.flatten(),\n",
    "            ADCP.bin_depth.values.flatten(), \n",
    "            ADCP['Sh_'+letter].values.flatten(), \n",
    "            xi=xaxis, yi=yaxis, fn='mean')\n",
    "\n",
    "        # Integrate shear vertically\n",
    "        _bd = ~np.isfinite(Sh) # Preserve what are originally NaN values to recover later as need conversion to 0 for cumsum-\n",
    "        Sh = np.nan_to_num(Sh) # Replace NaNs with 0 for cumsum\n",
    "        V = np.cumsum(Sh,axis=0)*y_res # Cumulative sum of shear to recover velocity profile\n",
    "        V[_bd] = np.NaN # Return NaNs to their rightful place.\n",
    "        V = V - np.tile(np.nanmean(V, axis=0), (np.shape(V)[0],1)) # Make mean of baroclinic profiles equal to 0\n",
    "\n",
    "        # Grid DAC\n",
    "        DAC,XI,YI = sx.grid2d(\n",
    "            data.data.profileNum.values,\n",
    "            data.data.LEGATO_PRESSURE.values, \n",
    "            data.data['DAC_'+letter].values, \n",
    "            xi=xaxis, yi=yaxis, fn='mean')\n",
    "\n",
    "        # Grid vertical speed\n",
    "        dPdz,XI,YI = sx.grid2d(\n",
    "            data.data.profileNum.values,\n",
    "            data.data.LEGATO_PRESSURE.values, \n",
    "            data.data['speed_vert'].values, \n",
    "            xi=xaxis, yi=yaxis, fn='mean')\n",
    "\n",
    "        # Grid salinity\n",
    "        SA,XI,YI = sx.grid2d(\n",
    "            data.data.profileNum.values,\n",
    "            data.data.LEGATO_PRESSURE.values, \n",
    "            data.data.sa.values, \n",
    "            xi=xaxis, yi=yaxis, fn='median')\n",
    "\n",
    "        # Seconds spent in each depth bin, to weight referencing\n",
    "        SpB = y_res / dPdz\n",
    "        SpB[np.isinf(SpB)] = 0\n",
    "        strictness = 1\n",
    "        SpB_std = np.nanstd(SpB.flatten())\n",
    "        SpB[ np.abs(SpB) > (strictness*SpB_std) ] = strictness*SpB_std\n",
    "\n",
    "        # Baroclinic velocity, weighted by depth residence time, should be equal to DAC\n",
    "        # So the reference to add to a baroclinic profile of mean = 0 is the DAC - the weighted baroclinic velocity.    \n",
    "        Ref = np.nanmean(DAC, axis=0)  -  np.nansum(V*SpB, axis=0)/np.nansum(SpB, axis=0)\n",
    "\n",
    "        # Now we reference the velocity\n",
    "        V = V +  np.tile(Ref, (np.shape(V)[0],1))\n",
    "        out['ADCP_'+letter] = V\n",
    "\n",
    "        ## PLOT 1\n",
    "        plt.subplot(5,1, pstep+1)\n",
    "        plt.pcolormesh(taxis,yaxis,V,cmap=cmo.balance,shading='auto')\n",
    "        plt.clim(np.array([-1,1])*0.5)\n",
    "        plt.colorbar()\n",
    "        [plt.axvline(x, color='k', alpha=0.3) for x in days]\n",
    "        plt.contour(taxis,yaxis,SA,np.linspace(35.5,38.5,6),colors='k',alpha=0.3)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.xlabel('Yo number')\n",
    "        plt.xlabel('Depth')\n",
    "        plt.title(letter+'-ward velocity (m.s-1)')\n",
    "        \n",
    "        ## PLOT 2\n",
    "        plt.subplot(5,2, pstep+5)\n",
    "        plt.plot(taxis,np.nanmean(V, axis=0),'-k',alpha=0.5, linewidth=3)\n",
    "        plt.plot(taxis,np.nanmean(DAC, axis=0),':y',alpha=0.5, linewidth=3)\n",
    "        plt.legend(('ADCP '+letter,'DAC '+letter))\n",
    "        plt.ylim([-0.2,0.2])\n",
    "        \n",
    "        ## PLOT 3\n",
    "        plt.subplot(5,2, pstep+7)\n",
    "        max_depth = 26\n",
    "        _gd = np.isfinite(dN+dE)\n",
    "        if pstep==0:\n",
    "            plt.plot(pd.to_datetime(dT[_gd]),dE[_gd],':og', alpha=0.8)\n",
    "        else:\n",
    "            plt.plot(pd.to_datetime(dT[_gd]),dN[_gd],':og', alpha=0.8)   \n",
    "        V_surf = np.nanmean(V[:max_depth,:], axis=0)\n",
    "        plt.plot(taxis[np.isfinite(V_surf)],V_surf[np.isfinite(V_surf)],'-ok',alpha=0.5)\n",
    "        plt.legend(('Surf. drift '+letter,'Near surf. ADCP '+letter))\n",
    "        plt.ylim([-0.5,0.5])\n",
    "    \n",
    "        ## PLOT 4\n",
    "        plt.subplot(5,2, pstep+9)\n",
    "        \n",
    "        indices = np.flip(np.cumsum(np.flip(np.full_like(V,1)*np.isfinite(V),axis=0),axis=0),axis=0)\n",
    "        indices[indices > 10] = np.NaN\n",
    "        indices[np.isfinite(indices)] = 1\n",
    "        bottom_V = np.nanmean(V*indices, axis=0)   \n",
    "        plt.plot(taxis,RunningMean(bottom_V,1),'-r',marker='.',alpha=0.8)\n",
    "        \n",
    "        ind = np.arange(len(ADCP['time'])) #np.isfinite(ADCP['BT_'+letter].values)\n",
    "        bt_t = ADCP['time'].isel(time=ind).values\n",
    "        bt = (ADCP[letter]-ADCP['BT_'+letter]).isel(time=ind).mean('gridded_bin').values\n",
    "        bt_std = (ADCP[letter]-ADCP['BT_'+letter]).isel(time=ind).std('gridded_bin').values\n",
    "    \n",
    "        bt_smooth = 30\n",
    "        plt.plot( bt_t , RunningMean(bt,bt_smooth), '-k', marker='.', alpha=0.5)\n",
    "        plt.ylim([-0.15,0.15])\n",
    "        plt.legend(('ADCP near bottom '+letter,'Bottom track '+letter))\n",
    "        \n",
    "        \n",
    "    plt.savefig(filename[:filename.rfind('/')+1]+'currents.png', bbox_inches='tight')\n",
    "    \n",
    "_verify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9005272",
   "metadata": {},
   "source": [
    "# VI. Grid and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362e1a0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _grid_glider_data(data): \n",
    "    exclude = ['AD2CP_ALT', 'AD2CP_HEADING', 'AD2CP_PITCH', 'AD2CP_PRESSURE',\n",
    "    'AD2CP_ROLL', 'AROD_FT_DO', 'AROD_FT_TEMP', 'Altitude', 'AngCmd',\n",
    "    'AngPos', 'BallastCmd', 'BallastPos', 'DeadReckoning', 'Declination',\n",
    "    'Depth', 'DesiredH','LinCmd', 'LinPos','NAV_DEPTH', 'NAV_LATITUDE', 'NAV_LONGITUDE',\n",
    "    'NAV_RESOURCE', 'NavState', 'Pa', 'Pitch', 'Roll', 'SecurityLevel', 'Temperature',\n",
    "    'Timestamp', 'Unnamed: 22', 'Unnamed: 28', 'Voltage', 'missionNum','Lat','Lon']\n",
    "\n",
    "    variables = data.columns\n",
    "    \n",
    "    variables = [x for x in variables if x not in exclude]\n",
    "    grid = lambda name : sx.grid2d(data.profileNum.values, data.LEGATO_PRESSURE.values, data[name].values, xi=xaxis, yi=yaxis, fn='mean')[0]\n",
    "\n",
    "    for varname in tqdm(variables):\n",
    "        try:\n",
    "            out[varname] = grid(varname)\n",
    "            plt.close('all')\n",
    "            plt.figure(figsize=(14,5))\n",
    "            plt.pcolormesh(taxis,yaxis,out[varname],cmap=cmo.haline)\n",
    "            plt.colorbar()\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.savefig(filename[:filename.rfind('/')+1]+varname+'.png', bbox_inches='tight')\n",
    "            plt.close('all')\n",
    "        except:\n",
    "            print('Variable \"'+varname+'\" failed to grid.')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7041b242",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "out = _grid_glider_data(data.data)\n",
    "\n",
    "ADCP_pnum = np.tile(ADCP.profileNum, (len(ADCP.gridded_bin),1)).T\n",
    "out['Sh_E'] = sx.grid2d(ADCP_pnum.flatten(), ADCP.bin_depth.values.flatten(), ADCP.Sh_E.values.flatten(), xi=xaxis, yi=yaxis, fn='mean')[0]\n",
    "out['Sh_N'] = sx.grid2d(ADCP_pnum.flatten(), ADCP.bin_depth.values.flatten(), ADCP.Sh_N.values.flatten(), xi=xaxis, yi=yaxis, fn='mean')[0]\n",
    "out['Sh_U'] = sx.grid2d(ADCP_pnum.flatten(), ADCP.bin_depth.values.flatten(), ADCP.Sh_U.values.flatten(), xi=xaxis, yi=yaxis, fn='mean')[0]\n",
    "out['Heading'] = sx.grid2d(ADCP.profileNum.values.flatten(), ADCP.Pressure.values.flatten(), ADCP.Heading.values.flatten(), xi=xaxis, yi=yaxis, fn='mean')[0]\n",
    "\n",
    "# out['ABS'] = sx.grid2d(ADCP_pnum.flatten(), ADCP.bin_depth.values.flatten(), \n",
    "#                           (ADCP.A1.values.flatten()+ADCP.A2.values.flatten()+ADCP.A3.values.flatten()+ADCP.A4.values.flatten())/4,\n",
    "#                           xi=xaxis, yi=yaxis, fn='mean')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006f877-2e05-4d53-8307-0bd6c34a8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.linspace(0,np.max(yaxis),15)\n",
    "np.mean(np.diff(depths))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f2270-facd-4d5b-a5da-1094e9bb3f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_depth_bias():\n",
    "    \n",
    "    north = np.gradient(out['latitude'],axis=1) > 0\n",
    "    south = np.gradient(out['latitude'],axis=1) < 0\n",
    "    \n",
    "    up = np.remainder(out['profileNum'],2) == 0\n",
    "    down = np.remainder(out['profileNum'],2) == 1\n",
    "    \n",
    "    \n",
    "    depths = np.linspace(0,np.max(yaxis)-5,20)\n",
    "    drange = np.mean(np.diff(depths))/2\n",
    "    bins = np.linspace(-1,1,100) * 0.5\n",
    "    \n",
    "    variables = ['ADCP_E','ADCP_N']\n",
    "    \n",
    "    plt.figure(figsize=(20,7))\n",
    "    \n",
    "    for idx,var in enumerate(variables):\n",
    "        plt.subplot(1,3,idx+1)\n",
    "        plt.axvline(0,color='k')\n",
    "\n",
    "        for idx, d in enumerate(depths):\n",
    "            depth = (np.abs(out['LEGATO_PRESSURE'] - d) < drange)\n",
    "\n",
    "            N,_ = np.histogram(out[var][(north & depth)],bins=bins,density=True)\n",
    "            S,_ = np.histogram(out[var][(south & depth)],bins=bins,density=True)\n",
    "\n",
    "            Nm = np.nanmean(out[var][(north & depth)])\n",
    "            Sm = np.nanmean(out[var][(south & depth)])\n",
    "\n",
    "            N[N==0] = np.NaN\n",
    "            S[S==0] = np.NaN\n",
    "\n",
    "            SF = 1\n",
    "\n",
    "            plt.fill_between(bins[1:],SF*N-float(d),-float(d),color='r',alpha=0.5)\n",
    "            plt.fill_between(bins[1:],SF*S-float(d),-float(d),color='b',alpha=0.5)\n",
    "            plt.plot(bins[1:],SF*N-float(d),'-r')\n",
    "            plt.plot(bins[1:],SF*S-float(d),'-b')\n",
    "            plt.plot([Nm,Sm],np.array([1,1])*-float(d),'-kd')\n",
    "\n",
    "        plt.ylabel('Depth (m) / '+str(SF)+'*PDF')\n",
    "        plt.xlabel('Velocity')\n",
    "        plt.legend(('Zero','Northward travel','Southward travel'))\n",
    "        plt.title(var)\n",
    "        \n",
    "    plt.subplot(133)    \n",
    "    plt.axvline(0,color='k')\n",
    "\n",
    "    for idx, d in enumerate(depths):\n",
    "        depth = (np.abs(out['LEGATO_PRESSURE'] - d) < drange)\n",
    "\n",
    "        \n",
    "        N,_ = np.histogram(np.sqrt(out['ADCP_E']**2 + out['ADCP_N']**2)[(north & depth)],bins=bins,density=True)\n",
    "        S,_ = np.histogram(np.sqrt(out['ADCP_E']**2 + out['ADCP_N']**2)[(south & depth)],bins=bins,density=True)\n",
    "\n",
    "        Nm = np.nanmean(np.sqrt(out['ADCP_E']**2 + out['ADCP_N']**2)[(north & depth)])\n",
    "        Sm = np.nanmean(np.sqrt(out['ADCP_E']**2 + out['ADCP_N']**2)[(south & depth)])\n",
    "\n",
    "        N[N==0] = np.NaN\n",
    "        S[S==0] = np.NaN\n",
    "\n",
    "        SF = 1\n",
    "\n",
    "        plt.fill_between(bins[1:],SF*N-float(d),-float(d),color='r',alpha=0.5)\n",
    "        plt.fill_between(bins[1:],SF*S-float(d),-float(d),color='b',alpha=0.5)\n",
    "        plt.plot(bins[1:],SF*N-float(d),'-r')\n",
    "        plt.plot(bins[1:],SF*S-float(d),'-b')\n",
    "        plt.plot([Nm,Sm],np.array([1,1])*-float(d),'-kd')\n",
    "\n",
    "    plt.ylabel('Depth (m) / '+str(SF)+'*PDF')\n",
    "    plt.xlabel('Velocity')\n",
    "    plt.legend(('Zero','Northward travel','Southward travel'))\n",
    "    plt.title('MAG')\n",
    "\n",
    "    plt.savefig(filename[:filename.rfind('/')+1]+'ADCP_dsitribution.png', bbox_inches='tight')\n",
    "\n",
    "    return None\n",
    "\n",
    "verify_depth_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b52cc3-2dba-4ba6-b05e-857d4bf5a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportCSVfiles():\n",
    "    for key in out:\n",
    "        print(key)\n",
    "        np.savetxt(filename[:filename.rfind('/')+1]+key+'.csv', out[key], delimiter=\",\") \n",
    "# exportCSVfiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6eab90-00ea-4fa4-b383-eaa23873e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad851471-d6f5-491d-937f-5874e6f65729",
   "metadata": {
    "tags": []
   },
   "source": [
    "# END OF FILE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
