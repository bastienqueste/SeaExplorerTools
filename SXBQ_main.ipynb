{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e70593d-b000-40d0-aa55-a9cbeca2879c",
   "metadata": {},
   "source": [
    "# SEAEXPLORER DATA PROCESSING CHAIN\n",
    "\n",
    "2021/09/07 - Bastien Queste\n",
    "\n",
    "# PACKAGES : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e4265-4828-43e4-9806-0455102e37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, os, gsw, gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import fmin\n",
    "from tqdm import tqdm\n",
    "\n",
    "import SXBQ as sx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "%matplotlib widget\n",
    "\n",
    "importlib.reload(sx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a9502-eb47-4df4-a96f-8d01dc2746d7",
   "metadata": {},
   "source": [
    "# SETTINGS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db3998-713b-4323-b461-9f72ff286edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "missions = {'SEA063':np.arange(17,23)}\n",
    "pqt_files = []\n",
    "pqt_folders = []\n",
    "for k in missions.keys():\n",
    "    for m in missions[k]:\n",
    "        pqt_files.append('D:/Storage/Dropbox/Jupyter/Data/Bornholm_'+k+'_M'+str(m)+'.pqt')\n",
    "        pqt_folders.append('D:/Storage/Dropbox/VOTO_Data/7_SAMBA_004/SEA063_PLD089/SEA063_M'+str(m)+'\\2_Sorted\\4_PLD_raw')\n",
    "        pqt_folders.append('D:/Storage/Dropbox/VOTO_Data/7_SAMBA_004/SEA063_PLD089/SEA063_M'+str(m)+'\\2_Sorted\\2_NAV')\n",
    "pqt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2939fe9-8c95-4b59-836f-fbb03d5fda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = {\n",
    "    'convert_to_pqt': False, #'D:/Storage/Dropbox/Jupyter/', # False or list of directories to process\n",
    "    'merge_pqt': False, # False or list of .pqt to load\n",
    "    'RBR_corr': True, # True = regress, False = use raw, 1x4 array of coefficients = use supplied coefficients\n",
    "    'flight_model': True,\n",
    "    'process_adcp':False,\n",
    "    'save_file': 'D:/Storage/Dropbox/Jupyter/Data/Bornholm_SEA055_M24.pqt' #'D:/Storage/Dropbox/Jupyter/Data/Bornholm_055_061_combined.pqt' # False or file path\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95737f-3ef2-4f68-937d-78931f7919b3",
   "metadata": {},
   "source": [
    "# CONVERT TO PARQUET FROM RAW : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c0459-1c80-4dd9-ab08-6ddec836175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sx)\n",
    "\n",
    "if todo['convert_to_pqt']:\n",
    "    print('Converting data to parquet...')\n",
    "    def convert_to_pqt():\n",
    "        data = sx.sxdf(todo['convert_to_pqt'])\n",
    "        data.save(todo['save_file'])\n",
    "    convert_to_pqt()\n",
    "    gc.collect()\n",
    "else:\n",
    "    print('Skipping conversion to parquet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d2ea6-127c-419e-8b75-fff7e0f5bfcc",
   "metadata": {},
   "source": [
    "# MERGE PQT FILES : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd4c343-155a-4062-b098-fb174430cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if todo['merge_pqt']:\n",
    "    print('Loading parquet files...')\n",
    "    def merge_pqt():\n",
    "        data = sx.sxdf()\n",
    "        for k,save_file in enumerate(todo['merge_pqt']):\n",
    "            _tmp = pd.read_parquet(save_file)\n",
    "            _tmp['diveNum'] = _tmp['diveNum'] + (k * 1e6)\n",
    "            data.data = data.data.append(_tmp,ignore_index=True)\n",
    "            gc.collect()\n",
    "\n",
    "        data.save(todo['save_file'])\n",
    "    \n",
    "    merge_pqt()\n",
    "    gc.collect()\n",
    "else:\n",
    "    print('Skipping parquet file loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb39c82-770c-411b-bff7-9b8cc5eeb842",
   "metadata": {},
   "source": [
    "# LOAD\n",
    "Runs in all cases as previous ones save and clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239cefa1-5663-4915-a421-751330494cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "data = sx.sxdf()\n",
    "data.data = pd.read_parquet(todo['save_file'])\n",
    "\n",
    "def delimitateProfiles():\n",
    "\n",
    "    #data.data.sort_values('Timestamp', ignore_index=True, inplace=True)\n",
    "    data.median_resample()\n",
    "\n",
    "    _gd = np.isfinite(data.data['diveNum'].values)\n",
    "    _, _tmp = np.unique( np.round(data.data['diveNum'].values[_gd]) ,return_inverse=True)\n",
    "\n",
    "    data.data.loc[_gd,'diveNum'] = np.round(_tmp+1)\n",
    "    data.data['diveNum'] = data.data['diveNum'].interpolate('nearest')\n",
    "        \n",
    "    data.data['profileNum'] = data.data['diveNum'].values*2\n",
    "    _tmp = data.data['NAV_RESOURCE'].interpolate('nearest').values\n",
    "    ind = (_tmp == 100) | (_tmp == 110) | (_tmp == 116)\n",
    "    data.data.loc[ind,'profileNum'] = data.data.loc[ind,'profileNum'] - 1\n",
    "\n",
    "delimitateProfiles()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601147da-7e5a-45ad-b103-9fea7073052b",
   "metadata": {},
   "source": [
    "# PRESSURE CORRECTION : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aafbb19-1ce8-4f87-9ee7-1ee3bd4942fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data['pressure'] = data.data['LEGATO_PRESSURE'].interpolate('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249a4751-ec91-46b5-a711-16756ffa402e",
   "metadata": {},
   "source": [
    "# RBR CORRECTION :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635d836-471c-438b-b035-2bb8acaad96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if todo['RBR_corr']:\n",
    "    print('Correcting RBR data...')\n",
    "    \n",
    "    def RBR_correction():\n",
    "        \n",
    "        if 'speed' in data.data:\n",
    "            flowSpeed = data.data.speed.interpolate('index').values\n",
    "        else:\n",
    "            print('Estimating flow speed...')\n",
    "            flowSpeed = np.abs(np.gradient(data.data.pressure,sx.date2float(data.data.Timestamp)) / np.sin(np.deg2rad(data.data.Pitch.interpolate('index')))).fillna(value=0.0001)\n",
    "            flowSpeed[flowSpeed > 1] = 1\n",
    "            \n",
    "        print('Aligning C-T...')\n",
    "        time = sx.date2float(data.data['Timestamp'])\n",
    "        temp = data.data['LEGATO_TEMPERATURE'].values\n",
    "        _gd = np.isfinite(time+temp)\n",
    "        lag = -0.92 * flowSpeed + 1.22 # from RBR\n",
    "        _interp = interp1d(time[_gd] - lag[_gd], temp[_gd], bounds_error=False, fill_value=np.NaN)\n",
    "        data.data['temperature'] = _interp(time)\n",
    "\n",
    "        print('Performing thermal mass correction...')\n",
    "        Fs = np.mean(1/np.gradient(time))\n",
    "        print('         Assuming a sampling frequency of '+str(Fs)+' Hz.')\n",
    "        \n",
    "\n",
    "        def _calcSal(temp, cond, pres, coefs):\n",
    "            a_offset = coefs[0]\n",
    "            a_slope = coefs[1]\n",
    "            t_offset = coefs[2]\n",
    "            t_slope = coefs[3]\n",
    "            alpha = a_offset + a_slope / flowSpeed\n",
    "            tau = t_offset + t_slope / np.sqrt(flowSpeed)\n",
    "            #tau = 11 # Parameter for Lueck and Picklo (1990)\n",
    "            #alpha = 0.57/tau + 0.03122 # Parameter for Lueck and Picklo (1990)\n",
    "            \n",
    "            alpha[~np.isfinite(alpha)] = a_offset\n",
    "            tau[~np.isfinite(tau)] = t_offset\n",
    "            \n",
    "            beta = 1/tau # Parameter for Lueck and Picklo (1990)\n",
    "            fn = Fs/2 # Nyquist frequency\n",
    "\n",
    "            a = 4*fn*alpha*tau/(1+4*fn*tau) # Parameter for Lueck and Picklo (1990)\n",
    "            b = 1-2*a/alpha # Parameter for Lueck and Picklo (1990)\n",
    "\n",
    "            # Compute temperature correction to obtained water temperature within the conductivity cell (Morison, 1994)\n",
    "            _internal_bias = np.full_like(temp,0)\n",
    "\n",
    "            for sample in np.arange(1,len(_internal_bias)):\n",
    "                # Recursive filter from Morison (1994)\n",
    "                # if np.isfinite(temp[sample-1]):\n",
    "                _internal_bias[sample] = -b[sample] * _internal_bias[sample-1] + a[sample] * (temp[sample] - temp[sample-1])\n",
    "            return gsw.SP_from_C(cond, temp + _internal_bias, pres) # Practical salinity\n",
    "                \n",
    "        def _regressSal():\n",
    "            _dives = np.unique(data.data.diveNum)[np.linspace(0, len(np.unique(data.data.diveNum))-1, 20).astype('int')] # Number of dives to regress over, 10 min, 100 probably good.\n",
    "            _dives = (np.isin(data.data.diveNum, _dives)) & (np.isfinite(data.data.temperature))\n",
    "            _temp = data.data.temperature[_dives]\n",
    "            _cond = data.data.LEGATO_CONDUCTIVITY[_dives]\n",
    "            _pres = data.data.pressure[_dives]\n",
    "            \n",
    "            # Use these generic values to scale parameters to same order of magnitude to help fmin.\n",
    "            scaler = np.array([0.0135, 0.0264, 7.1499, 2.7858])\n",
    "            \n",
    "            def _PolyArea(x,y):\n",
    "                _gg = np.isfinite(x+y)\n",
    "                return 0.5*np.abs(np.dot(x[_gg],np.roll(y[_gg],1))-np.dot(y[_gg],np.roll(x[_gg],1)))\n",
    "        \n",
    "            def _scoreFunction(x_vals):\n",
    "                return _PolyArea( _calcSal(_temp, _cond, _pres, x_vals*scaler) , _temp)\n",
    "            \n",
    "            print('Beginning regression (slow)...')\n",
    "            print('         Initial minimisation score: '+str(_scoreFunction([1,1,1,1]))+'.')\n",
    "            R = fmin(_scoreFunction, [1,1,1,1], disp=False, full_output=True, maxiter=200)\n",
    "            print('         Final minimisation score: '+str(_scoreFunction(R[0]))+'.')\n",
    "            return R[0]*scaler\n",
    "        \n",
    "        if todo['RBR_corr'] is True:\n",
    "            coefs = _regressSal()\n",
    "            print('Regressed coefficients:')\n",
    "\n",
    "        else:\n",
    "            coefs = todo['RBR_corr']\n",
    "            print('Correcting using supplied coefficients:')\n",
    "        \n",
    "        print(coefs)\n",
    "        print('Applying correction to all data (slow)...')\n",
    "        # We have to interpolate temperature here as it's a recursive filter and NaNs propagate.\n",
    "        # Both temperature and the alpha and tau parameters have to be finite.\n",
    "        # This means interpolate and fill temperature and flowSpeed, \n",
    "        # and avoid divisions by zero (with flowSpeed = 0 or pitch = 0)\n",
    "        data.data['salinity'] = _calcSal(\n",
    "            data.data.temperature.interpolate('index').fillna(method='backfill'), \n",
    "            data.data.LEGATO_CONDUCTIVITY, \n",
    "            data.data.pressure, \n",
    "            coefs)\n",
    "        \n",
    "        data.data.loc[~(abs(data.data['salinity']-data.data['LEGATO_SALINITY']) < 0.5),'salinity'] = np.NaN  # Can definitely play around with this threshold\n",
    "        \n",
    "    RBR_correction()\n",
    "    \n",
    "    print('Done.')\n",
    "else:\n",
    "    print('Using raw temperature and salinity')\n",
    "    data.data.rename(columns={\n",
    "        \"LEGATO_TEMPERATURE\": \"temperature\", \n",
    "        \"LEGATO_SALINITY\": \"salinity\"\n",
    "        },inplace=True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78876597-67bf-469f-a8f4-606c14a258b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if todo['RBR_corr']:\n",
    "    def verifyTScorr():\n",
    "        %matplotlib widget\n",
    "        plt.rcParams[\"figure.figsize\"] = (7,7)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        line, = ax.plot([0], [0], 'b-',linewidth=0.5)\n",
    "        line2, = ax.plot([0], [0], 'r-',linewidth=0.5)\n",
    "        plt.subplots_adjust(left=0.25, bottom=0.25)\n",
    "\n",
    "        t = data.data.LEGATO_TEMPERATURE.interpolate('index')\n",
    "        s = data.data.LEGATO_SALINITY.interpolate('index')\n",
    "        tc = data.data.temperature.interpolate('index')\n",
    "        sc = data.data.salinity.interpolate('index')\n",
    "        dn = np.round(data.data.diveNum.interpolate('nearest'))\n",
    "\n",
    "        XL = np.nanpercentile(s,[1,99])\n",
    "        YL = np.nanpercentile(t,[1,99])\n",
    "        plt.xlim(XL)\n",
    "        plt.ylim(YL)\n",
    "\n",
    "        plt.title('Red = corrected')\n",
    "\n",
    "        def update(dnum = 1):\n",
    "            line.set_xdata(s[dn == sdnum.val])\n",
    "            line.set_ydata(t[dn == sdnum.val])\n",
    "\n",
    "            line2.set_xdata(sc[data.data.diveNum == sdnum.val])\n",
    "            line2.set_ydata(tc[data.data.diveNum == sdnum.val])\n",
    "\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "        axdnum = plt.axes([0.25, 0.1, 0.65, 0.03])\n",
    "        sdnum = Slider(axdnum, 'Dive num', 0, np.nanmax(data.data.diveNum), valinit=0, valstep=1)\n",
    "        sdnum.on_changed(update)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    verifyTScorr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79624c25-e00a-4e73-b3e9-28652c8fc893",
   "metadata": {},
   "outputs": [],
   "source": [
    "if todo['RBR_corr']:\n",
    "    def verifyTScorr():\n",
    "        _u = np.remainder(data.data.profileNum,2) == 0\n",
    "        _d = np.remainder(data.data.profileNum,2) == 1 ## VERIFY\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        plt.subplot(211)\n",
    "        plt.scatter(data.data.salinity[_d],data.data.temperature[_d], 1,'r', alpha=0.01)\n",
    "        plt.scatter(data.data.salinity[_u],data.data.temperature[_u], 1,'b', alpha=0.01)\n",
    "        XL = np.nanpercentile(data.data.salinity,[0.1,99.9])\n",
    "        YL = np.nanpercentile(data.data.temperature,[0.1,99.9])\n",
    "        plt.xlim(XL)\n",
    "        plt.ylim(YL)\n",
    "        plt.title('Up vs Down - Corrected')\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.scatter(data.data.LEGATO_SALINITY[_d],data.data.LEGATO_TEMPERATURE[_d], 1,'r', alpha=0.01)\n",
    "        plt.scatter(data.data.LEGATO_SALINITY[_u],data.data.LEGATO_TEMPERATURE[_u], 1,'b', alpha=0.01)\n",
    "        XL = np.nanpercentile(data.data.LEGATO_SALINITY,[0.1,99.9])\n",
    "        YL = np.nanpercentile(data.data.LEGATO_TEMPERATURE,[0.1,99.9])\n",
    "        plt.xlim(XL)\n",
    "        plt.ylim(YL)\n",
    "        plt.title('Up vs Down - Uncorrected')\n",
    "\n",
    "    verifyTScorr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04231750-fb5e-468c-ab32-5c22f6b77f76",
   "metadata": {},
   "source": [
    "# GSW BASICS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a12dd3-de3d-484e-ba84-2c4414b00ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location\n",
    "data.data['lon'] = sx.parseGPS(data.data.NAV_LONGITUDE).interpolate('index').fillna(method='backfill')\n",
    "data.data['lat'] = sx.parseGPS(data.data.NAV_LATITUDE).interpolate('index').fillna(method='backfill')\n",
    "\n",
    "# Basic:\n",
    "data.data['sa'] = gsw.SA_from_SP(data.data['salinity'],data.data['pressure'],data.data['lon'],data.data['lat'])\n",
    "data.data['ct'] = gsw.CT_from_t(data.data['sa'],data.data['temperature'],data.data['pressure'])\n",
    "\n",
    "# Physical:\n",
    "data.data['sigma0'] = gsw.sigma0(data.data['sa'], data.data['ct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9190b6d-6e8c-48c1-96bc-84e80837ada9",
   "metadata": {},
   "source": [
    "# FLIGHT MODEL :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e969e-20e7-40c8-9241-efde4388caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sx)\n",
    "if todo['flight_model']:\n",
    "    print('Running flight model regression...')\n",
    "    \n",
    "    def flight_model():      \n",
    "        \n",
    "        flight = sx.SlocumModel(\n",
    "               data.data.Timestamp, \n",
    "               data.data.salinity.interpolate('index').values, \n",
    "               data.data.temperature.interpolate('index').values, \n",
    "               data.data.pressure.interpolate('index').values, \n",
    "               data.data.lon.interpolate('index').values, \n",
    "               data.data.lat.interpolate('index').values, \n",
    "               data.data.BallastPos.interpolate('index').values, \n",
    "               data.data.Pitch.interpolate('index').values, \n",
    "               data.data.profileNum.interpolate('nearest').values,\n",
    "               data.data.NAV_RESOURCE.interpolate('nearest').values,\n",
    "               mass=60.772) # Verify mass number !!\n",
    "\n",
    "        flight.regress()\n",
    "        \n",
    "        data.data['alpha'] = flight.alpha\n",
    "        data.data['speed'] = flight.speed\n",
    "        data.data['speed_vert'] = flight.speed_vert\n",
    "        data.data['speed_horz'] = flight.speed_horz\n",
    "        data.data['w_H2O'] = flight.w_H2O\n",
    "        \n",
    "        return flight\n",
    "       \n",
    "    flight = flight_model()\n",
    "    ind = flight._valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1efc7-3253-490d-a5a1-9740c19c5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if todo['flight_model']:\n",
    "    def verifyFlightModel():\n",
    "        ## VISUALISATIONS:\n",
    "        plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "        plt.figure() \n",
    "\n",
    "        plt.subplot(321)\n",
    "        V,XI,YI = sx.grid2d(data.data.loc[ind,'profileNum'],data.data.loc[ind,'pressure'],data.data.loc[ind,'w_H2O'], xi=1, yi=1)\n",
    "        plt.pcolor(XI/2,YI,V,shading='auto',cmap='coolwarm')\n",
    "        plt.colorbar()\n",
    "        plt.clim([-0.02,0.02])\n",
    "        #plt.ylim([0,300])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.title('W_H2O')\n",
    "        \n",
    "        plt.subplot(323)\n",
    "        plt.plot(XI[:,1],np.nansum(V,axis=1))\n",
    "\n",
    "        plt.subplot(322)\n",
    "        _ = plt.hist(data.data.loc[ind,'w_H2O'],np.linspace(-0.1,0.1,200))\n",
    "        ylim = plt.ylim()\n",
    "        for pt in np.nanpercentile(data.data.loc[ind,'w_H2O'],[5,25,50,75,95]):\n",
    "            plt.plot([pt,pt],ylim,':k')\n",
    "        plt.plot([0,0],ylim,'-r')\n",
    "        plt.title('W_H2O')\n",
    "        plt.xlim([-0.05,0.05])\n",
    "\n",
    "        ind2 = np.remainder(data.data['profileNum'],2) == 1 & ind\n",
    "        D,XI,YI = sx.grid2d(data.data.loc[ind2,'diveNum'],data.data.loc[ind2,'pressure'],data.data.loc[ind2,'w_H2O'], xi=1, yi=3)\n",
    "        ind2 = np.remainder(data.data['profileNum'],2) == 0 & ind\n",
    "        U,XI,YI = sx.grid2d(data.data.loc[ind2,'diveNum'],data.data.loc[ind2,'pressure'],data.data.loc[ind2,'w_H2O'], xi=1, yi=3)\n",
    "\n",
    "        plt.subplot(324)\n",
    "        plt.pcolor(XI,YI,D-U,shading='auto',cmap='coolwarm')\n",
    "        plt.colorbar()\n",
    "        plt.clim([-0.02,0.02])\n",
    "        #plt.ylim([0,300])\n",
    "        #plt.xlim([0,60*60*24*2])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.title('Down - Up W_H2O')\n",
    "        \n",
    "        plt.subplot(325)\n",
    "        plt.pcolor(XI,YI,D,shading='auto',cmap='coolwarm')\n",
    "        plt.colorbar()\n",
    "        plt.clim([-0.02,0.02])\n",
    "        #plt.ylim([0,300])\n",
    "        #plt.xlim([0,60*60*24*2])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.title('Downcasts')\n",
    "        \n",
    "        plt.subplot(326)\n",
    "        plt.pcolor(XI,YI,U,shading='auto',cmap='coolwarm')\n",
    "        plt.colorbar()\n",
    "        plt.clim([-0.02,0.02])\n",
    "        #plt.ylim([0,300])\n",
    "        #plt.xlim([0,60*60*24*2])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.title('Upcasts')\n",
    "        \n",
    "    verifyFlightModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a8bca-0e1e-46f8-8f28-bec592b9579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save(todo['save_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134f7d1-1fda-4256-98cc-b2db5db917fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9abf8d6-1d7b-43e0-a0d5-b1c8c2458edb",
   "metadata": {},
   "source": [
    "# NEXT STEPS .... ? :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
